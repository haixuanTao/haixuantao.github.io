<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Haixuan Xavier Tao</title>
                <meta name="robots" content="noindex" />
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
                <link rel="stylesheet" href="custom.css">
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="about-me.html">About Me</a></li><li class="chapter-item expanded "><a href="about-me/work.html"><strong aria-hidden="true">1.</strong> Work Experience</a></li><li class="chapter-item expanded "><a href="about-me/education.html"><strong aria-hidden="true">2.</strong> Education</a></li><li class="chapter-item expanded "><a href="about-me/skills.html"><strong aria-hidden="true">3.</strong> Skills</a></li><li class="chapter-item expanded affix "><li class="part-title">Latest Posts</li><li class="chapter-item expanded "><a href="03-deep_learning_in_rust.html"><strong aria-hidden="true">4.</strong> 07.2020 - Deep Learning in Rust</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="deep-learning/hardware.html"><strong aria-hidden="true">4.1.</strong> Hardware</a></li><li class="chapter-item expanded "><a href="deep-learning/preprocessing.html"><strong aria-hidden="true">4.2.</strong> Preprocessing</a></li><li class="chapter-item expanded "><a href="deep-learning/batch_inference.html"><strong aria-hidden="true">4.3.</strong> Batch Inference</a></li><li class="chapter-item expanded "><a href="deep-learning/bert-server.html"><strong aria-hidden="true">4.4.</strong> Bert Server</a></li><li class="chapter-item expanded "><a href="deep-learning/conclusion.html"><strong aria-hidden="true">4.5.</strong> Conclusion</a></li></ol></li><li class="chapter-item expanded "><a href="02-polars-vs-rust.html"><strong aria-hidden="true">5.</strong> 04.2020 - Rust v Polars</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="pandas-polars/polars.html"><strong aria-hidden="true">5.1.</strong> Polars</a></li><li class="chapter-item expanded "><a href="pandas-polars/020-reading.html"><strong aria-hidden="true">5.2.</strong> Reading</a></li><li class="chapter-item expanded "><a href="pandas-polars/021-apply.html"><strong aria-hidden="true">5.3.</strong> Apply</a></li><li class="chapter-item expanded "><a href="pandas-polars/22-merging.html"><strong aria-hidden="true">5.4.</strong> Merging</a></li><li class="chapter-item expanded "><a href="pandas-polars/23-groupby.html"><strong aria-hidden="true">5.5.</strong> Groupby</a></li><li class="chapter-item expanded "><a href="pandas-polars/24-conculsion.html"><strong aria-hidden="true">5.6.</strong> Conclusion</a></li></ol></li><li class="chapter-item expanded "><a href="01-pandas-vs-rust.html"><strong aria-hidden="true">6.</strong> 03.2020 - Pandas v Rust (#1 on Google)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="pandas-rust/010-reading.html"><strong aria-hidden="true">6.1.</strong> Reading</a></li><li class="chapter-item expanded "><a href="pandas-rust/011-filtering.html"><strong aria-hidden="true">6.2.</strong> Filtering</a></li><li class="chapter-item expanded "><a href="pandas-rust/012-groupby.html"><strong aria-hidden="true">6.3.</strong> Groupby</a></li><li class="chapter-item expanded "><a href="pandas-rust/013-mutation.html"><strong aria-hidden="true">6.4.</strong> Mutation</a></li><li class="chapter-item expanded "><a href="pandas-rust/014-merging.html"><strong aria-hidden="true">6.5.</strong> Merging</a></li><li class="chapter-item expanded "><a href="pandas-rust/15-conclusion.html"><strong aria-hidden="true">6.6.</strong> Conclusion</a></li></ol></li><li class="chapter-item expanded "><a href="00-scraping.html"><strong aria-hidden="true">7.</strong> 02.2020 - Scraping Rust v Python</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="scraping/synchronous.html"><strong aria-hidden="true">7.1.</strong> Synchronous</a></li><li class="chapter-item expanded "><a href="scraping/asynchronous.html"><strong aria-hidden="true">7.2.</strong> Asynchronous</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">Haixuan Xavier Tao</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="hey--welcome-to-my-portfolio-"><a class="header" href="#hey--welcome-to-my-portfolio-">Hey ü§ó Welcome to my Portfolio üî•</a></h1>
<img alt="me" src="me.jpeg" style="border-radius:10%; margin-left: auto; margin-top: 1em; margin-right: auto; display: block" width="400" />
<br/>
<p><a href="mailto:tao.xavier@outlook.com"><img src="https://img.shields.io/badge/tao.xavier@outlook.com-EA4335?logo=gmail&amp;logoColor=white" alt="Mail" /></a>
<a href="https://www.linkedin.com/in/haixuan-xavier-tao-7460b1102/"><img src="https://img.shields.io/badge/Haixuan_Xavier_Tao-0077B5?logo=linkedin&amp;logoColor=white" alt="Linkedin" /></a>
<a href="https://github.com/haixuanTao"><img src="https://img.shields.io/badge/HaixuanTao-fff?logo=github&amp;logoColor=black" alt="Github" /></a></p>
<p>Data Engineer belivieving in Rust for ML/IA engineering.</p>
<p>Searching for a great Rust ML/IA Engineer? Get in touch üì¨ <a href="mailto:tao.xavier@outlook.com">tao.xavier@outlook.com</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="work-experience"><a class="header" href="#work-experience">Work Experience</a></h1>
<h4 id="data-engineer--central-bank-of-francediv-classrightdec-2020---nowdiv"><a class="header" href="#data-engineer--central-bank-of-francediv-classrightdec-2020---nowdiv">Data Engineer @ Central Bank of France<div class="right">Dec 2020 - Now</div></a></h4>
<p>Automating checks of Bank mortgage loans using NER, NLP, and CV.</p>
<blockquote>
<p><a href="https://events.linuxfoundation.org/lf-ai-data-day-eu-virtual/program/schedule/">üé§ Speaker at the Linux Foundation AI &amp; Data Days Europe on: Why ONNX Runtime Matters for Deploying AI in Institution.</a></p>
</blockquote>
<h4 id="researcher--insee-national-institute-for-stats-and-econ-studiesdiv-classrightsep-2020---dec-2020div"><a class="header" href="#researcher--insee-national-institute-for-stats-and-econ-studiesdiv-classrightsep-2020---dec-2020div">Researcher @ INSEE: National Institute for Stats and Econ Studies<div class="right">Sep 2020 - Dec 2020</div></a></h4>
<p>Measured population on a 100 meter grid of France at every hour based on mobile phone traffic data.</p>
<blockquote>
<p><a href="https://coms.events/NTTS2021/data/abstracts/en/abstract_0108.html">üìÉ Published a paper at NTTS 2021 on a novel approach for estimating population using Mobile Phone Data.</a></p>
</blockquote>
<h4 id="data-scientist-intern--boston-consulting-groupdiv-classrightjuly-2019---dec-2019div"><a class="header" href="#data-scientist-intern--boston-consulting-groupdiv-classrightjuly-2019---dec-2019div">Data Scientist Intern @ Boston Consulting Group<div class="right">July 2019 - Dec 2019</div></a></h4>
<p>Helped a large fashion retailer build a stocks optimizer for more than 100+ different markets.</p>
<h4 id="data-scientist-intern--bnp-paribasdiv-classrightjuly-2017---july-2018div"><a class="header" href="#data-scientist-intern--bnp-paribasdiv-classrightjuly-2017---july-2018div">Data Scientist Intern @ BNP Paribas<div class="right">July 2017 - July 2018</div></a></h4>
<p>Developed a corporate credit scoring and pricing algorithm leading to the lending of 100 millions ‚Ç¨ of unsecured loan for SME in the UK. </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="education"><a class="header" href="#education">Education</a></h1>
<h3 id="ecole-centrale-paris-centralesupelec-engineering-degree-div-classright2015---2019div"><a class="header" href="#ecole-centrale-paris-centralesupelec-engineering-degree-div-classright2015---2019div">Ecole Centrale Paris (CentraleSupelec), Engineering Degree <div class="right">2015 - 2019</div></a></h3>
<p>Majored in Applied Mathematics</p>
<p>Awards:</p>
<ul>
<li>2500 euros Innovation award for building an European Statistics search engine</li>
<li>2nd Place at BCG Gamma Data Challenge on Preventive Health Care Measure Optimization</li>
<li>1st Place with a 1500‚Ç¨ award at Schlumberger Hackathon on deep learning applied to Lithology</li>
</ul>
<h3 id="essec-business-school-msc-data-science--business-analyticsdiv-classright2018---2019div"><a class="header" href="#essec-business-school-msc-data-science--business-analyticsdiv-classright2018---2019div">ESSEC Business School, Msc Data Science &amp; Business Analytics<div class="right">2018 - 2019</div></a></h3>
<p>Double Major in Data Science and Business Strategy</p>
<p>Awards:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=M7GXZ3cjviM">[video] 1st Place at I-COM Data Science Hackathon - Warner Bros. Challenge</a>.</li>
<li>2nd Place at Oliver Wyman Data Challenge on Paris Public Parking Pricing </li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="skills"><a class="header" href="#skills">Skills</a></h1>
<h3 id="languages"><a class="header" href="#languages">Languages</a></h3>
<p>French, English, Mandarin (Basic reading and writing)</p>
<h3 id="coding-languages"><a class="header" href="#coding-languages">Coding Languages</a></h3>
<p>Rust, Python, C/C++, Javascript, Typescript, Git, Docker, Kubernetes</p>
<h3 id="sports"><a class="header" href="#sports">Sports</a></h3>
<p>Sailing ‚õµ and Kitesurfing üèÑ</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deep-learning-in-rust"><a class="header" href="#deep-learning-in-rust">Deep Learning in Rust</a></h1>
<p><a href="https://github.com/haixuantao/onnxruntime-rs"><img alt="github" src="https://img.shields.io/badge/onnxruntime_rs-fff?labelColor=000&logo=github" height="20"></a>
<a href="https://github.com/haixuantao/onnxruntime-rs/actions?query=branch%3Amaster"><img alt="build status" src="https://img.shields.io/github/workflow/status/haixuantao/onnxruntime-rs/Rust/master?" height="20"></a>
<a href="https://github.com/haixuanTao/onnxruntime-rs/"><img src="https://img.shields.io/github/stars/haixuanTao/onnxruntime-rs?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a></p>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>Building Deep Learning algorithms is paramount for doing Data Science in Rust. In this post, I show how:</p>
<ul>
<li>Rust can support GPU.</li>
<li>Rust can provide superior performance than Python and by how much.</li>
<li>Good and bad use case for Deep Learning in Rust.</li>
</ul>
<h2 id="state-of-the-art-of-deep-learning-in-rust"><a class="header" href="#state-of-the-art-of-deep-learning-in-rust">State of the art of Deep Learning in Rust</a></h2>
<p>Deep Learning in the Rust ecosystem is spread between native libraries like <a href="https://github.com/rust-ml/linfa">linfa</a> and C++ binding of common libraries like <a href="https://github.com/tensorflow/rust">Tensorflow</a>, <a href="https://github.com/LaurentMazare/tch-rs">Pytorch</a> and <a href="https://github.com/nbigaouette/onnxruntime-rs">Onnxruntime</a>.</p>
<p>I have found <a href="https://github.com/nbigaouette/onnxruntime-rs">onnxruntime-rs</a> to be a convenient crate for DL offering:</p>
<ul>
<li>the ability to load sklearn, tensorflow and pytorch model.</li>
<li>superior performance than native Pytorch or Tensorflow.</li>
<li>a small bundle size ~30Mb compared to <a href="https://github.com/pytorch/pytorch/issues/34058">tch-rs</a> 1.2 Gb bundle. </li>
</ul>
<p>‚û°Ô∏è this post is therefore going to be based on onnxruntime-rs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hardware"><a class="header" href="#hardware">Hardware</a></h1>
<p>Initially, onnxruntime-rs did not support GPU / CUDA despite having a C API.</p>
<p>But by tweaking <a href="https://github.com/nbigaouette/onnxruntime-rs">Onnxruntime-rs</a>, I could use the GPU C API and run DL Inference on GPU. </p>
<p>I opened a PR: <a href="https://github.com/nbigaouette/onnxruntime-rs/pull/87">https://github.com/nbigaouette/onnxruntime-rs/pull/87</a> providing the CUDA support for Linux and Windows.</p>
<p>And with similar work, a majority of the acceleration hardware could be added actually.</p>
<h2 id="gpu-support"><a class="header" href="#gpu-support">GPU Support</a></h2>
<p>To enable GPU support, I had to:</p>
<ul>
<li>add 2 header files in bindgen's <code>wrapper.h</code> file as follows: </li>
</ul>
<pre><code class="language-c">#include &quot;onnxruntime_c_api.h&quot;
#if !defined(__APPLE__)
  #include &quot;cpu_provider_factory.h&quot;
  #include &quot;cuda_provider_factory.h&quot;
#endif
</code></pre>
<ul>
<li>Add a feature flag:</li>
</ul>
<pre><code class="language-toml">[build-dependencies]
cuda = []
</code></pre>
<ul>
<li>add a safe API to the newly added bindings:</li>
</ul>
<pre><code class="language-rust noplaypen">    /// Set the session to use cpu
    #[cfg(feature = &quot;cuda&quot;)]
    pub fn use_cpu(self, use_arena: i32) -&gt; Result&lt;SessionBuilder&lt;'a&gt;&gt; {
        unsafe {
            sys::OrtSessionOptionsAppendExecutionProvider_CPU(self.session_options_ptr, use_arena);
        }
        Ok(self)
    }

    /// Set the session to use cuda
    #[cfg(feature = &quot;cuda&quot;)]
    pub fn use_cuda(self, device_id: i32) -&gt; Result&lt;SessionBuilder&lt;'a&gt;&gt; {
        unsafe {
            sys::OrtSessionOptionsAppendExecutionProvider_CUDA(self.session_options_ptr, device_id);
        }
        Ok(self)
    }
</code></pre>
<ul>
<li>Generate bindings for Linux:</li>
</ul>
<pre><code class="language-bash">&gt;&gt;&gt; cargo build --package onnxruntime-sys --features &quot;generate-bindings cuda&quot; --target x86_64-unknown-linux-gnu
</code></pre>
<ul>
<li>Generate bindings for Windows through a Windows VM:</li>
</ul>
<pre><code class="language-bash">&gt;&gt;&gt; cargo build --features &quot;generate-bindings cuda&quot; --target x86_64-pc-windows-msvc
</code></pre>
<ul>
<li>Modify github CI for autonomous build test:</li>
</ul>
<pre><code class="language-yaml">      - name: Download prebuilt archive (GPU, x86_64-unknown-linux-gnu)
        uses: actions-rs/cargo@v1
        with:
          command: build
          args: --target x86_64-unknown-linux-gnu --features cuda
      - name: Verify prebuilt archive downloaded (GPU, x86_64-unknown-linux-gnu)
        run: ls -lh target/x86_64-unknown-linux-gnu/debug/build/onnxruntime-sys-*/out/onnxruntime-linux-x64-gpu-1.*.tgz
      # ******************************************************************
      - name: Download prebuilt archive (GPU, x86_64-pc-windows-msvc)
        uses: actions-rs/cargo@v1
        with:
          command: build
          args: --target x86_64-pc-windows-msvc --features cuda
      - name: Verify prebuilt archive downloaded (GPU, x86_64-pc-windows-msvc)
        run: ls -lh target/x86_64-pc-windows-msvc/debug/build/onnxruntime-sys-*/out/onnxruntime-win-gpu-x64-1.*.zip
</code></pre>
<ul>
<li>As well as documentation.</li>
</ul>
<h2 id="performance"><a class="header" href="#performance">Performance</a></h2>
<table><thead><tr><th></th><th>Time per phrase</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Rust ONNX CPU</td><td>~125ms</td><td></td></tr>
<tr><td><strong>Rust ONNX GPU</strong></td><td><strong>~10ms</strong></td><td><strong>x12</strong>üî•</td></tr>
</tbody></table>
<p><em>Note: I have a six cores CPU and a GTX 1050 GPU.</em></p>
<p>As expected, the GPU drastically reduced the time of inference.</p>
<p>However, I did not found significant speedup between Onnxruntime Rust and Onnxruntime Python.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="preprocessing"><a class="header" href="#preprocessing">Preprocessing</a></h1>
<p>Preprocessing for Deep Learning is inevitable and can be very expensive. In the case of NLP, preprocessing translates to tokenizing. </p>
<p>To compare performance, I used HuggingFace tokenizer which is implemented in Rust, in Python and in Rust-Pyo3 Python.</p>
<p>The code is as follows for the python native tokenizer:</p>
<pre><code class="language-python">from transformers import BertTokenizer

PRE_TRAINED_MODEL_NAME = &quot;bert-base-cased&quot;

tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)

encoding = tokenizer(
        df[&quot;Title&quot;].to_numpy().tolist(),
        add_special_tokens=True,
        max_length=60,
        return_token_type_ids=False,
        padding=&quot;max_length&quot;,
        truncation=True,
        return_attention_mask=True,
        return_tensors=&quot;np&quot;,
    )
</code></pre>
<p>The Rust-Python Bertokenizer:</p>
<pre><code class="language-python">from transformers import BertTokenizerFast

PRE_TRAINED_MODEL_NAME = &quot;bert-base-cased&quot;

tokenizer = BertTokenizerFast.from_pretrained(PRE_TRAINED_MODEL_NAME)

encoding = tokenizer(
        df[&quot;Title&quot;].to_numpy().tolist(),
        add_special_tokens=True,
        max_length=60,
        return_token_type_ids=False,
        padding=&quot;max_length&quot;,
        truncation=True,
        return_attention_mask=True,
        return_tensors=&quot;np&quot;,
    )
</code></pre>
<p>And, the native Rust HuggingFace Tokenizer:</p>
<pre><code class="language-rust noplaypen">
use tokenizers::models::wordpiece::WordPieceBuilder;
use tokenizers::normalizers::bert::BertNormalizer;
use tokenizers::pre_tokenizers::bert::BertPreTokenizer;
use tokenizers::processors::bert::BertProcessing;
use tokenizers::tokenizer::AddedToken;
use tokenizers::tokenizer::{EncodeInput, Encoding, Tokenizer};
use tokenizers::utils::padding::{PaddingDirection::Right, PaddingParams, PaddingStrategy::Fixed};
use tokenizers::utils::truncation::TruncationParams;
use tokenizers::utils::truncation::TruncationStrategy::LongestFirst;

fn main() -&gt; std::result::Result&lt;(), OrtError&gt; {
    let vocab_path = &quot;./src/vocab.txt&quot;;
    let wp_builder = WordPieceBuilder::new()
        .files(vocab_path.into())
        .continuing_subword_prefix(&quot;##&quot;.into())
        .max_input_chars_per_word(100)
        .unk_token(&quot;[UNK]&quot;.into())
        .build()
        .unwrap();

    let mut tokenizer = Tokenizer::new(Box::new(wp_builder));
    tokenizer.with_pre_tokenizer(Box::new(BertPreTokenizer));
    tokenizer.with_truncation(Some(TruncationParams {
        max_length: 60,
        strategy: LongestFirst,
        stride: 0,
    }));
    tokenizer.with_post_processor(Box::new(BertProcessing::new(
        (&quot;[SEP]&quot;.into(), 102),
        (&quot;[CLS]&quot;.into(), 101),
    )));
    tokenizer.with_normalizer(Box::new(BertNormalizer::new(true, true, false, false)));
    tokenizer.add_special_tokens(&amp;[
        AddedToken {
            content: &quot;[PAD]&quot;.into(),
            single_word: false,
            lstrip: false,
            rstrip: false,
        },
        AddedToken {
            content: &quot;[CLS]&quot;.into(),
            single_word: false,
            lstrip: false,
            rstrip: false,
        },
        AddedToken {
            content: &quot;[SEP]&quot;.into(),
            single_word: false,
            lstrip: false,
            rstrip: false,
        },
        AddedToken {
            content: &quot;[MASK]&quot;.into(),
            single_word: false,
            lstrip: false,
            rstrip: false,
        },
    ]);
    tokenizer.with_padding(Some(PaddingParams {
        strategy: Fixed(60),
        direction: Right,
        pad_id: 0,
        pad_type_id: 0,
        pad_token: &quot;[PAD]&quot;.into(),
    }));

    // ...
    
    let input_ids = tokenizer.encode_batch(df, true).unwrap();
    
    Ok(())
}
</code></pre>
<h2 id="performance-1"><a class="header" href="#performance-1">Performance</a></h2>
<table><thead><tr><th></th><th>Time per phrase</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Python BertTokenizer</td><td>1000Œºs</td><td></td></tr>
<tr><td>Python BertTokenizerFast</td><td>200-600Œºs</td><td>x2.5 üî•</td></tr>
<tr><td><strong>Rust <a href="https://docs.rs/tokenizers/0.10.1/tokenizers/">Tokenizer</a></strong></td><td><strong>50-150Œºs</strong></td><td><strong>x4</strong> üî•</td></tr>
</tbody></table>
<p>You can tokenize 4 times faster in Rust than Python, with the same Hugging Face Tokenizer library.</p>
<p>Preprocessing can be very performant in Rust, making a case that Rust can outperform Python for Deep Learning.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="batch-inference-running-bert-on-10k-phrases"><a class="header" href="#batch-inference-running-bert-on-10k-phrases">Batch inference: Running BERT on 10k phrases.	</a></h2>
<p>At work, we often develop Deep Learning model to be used on large batches of data.</p>
<p>To see if Rust can improve this usecase, I trained a BERT-like model and infered 10k phrases using Python and Rust.</p>
<h3 id="performance-2"><a class="header" href="#performance-2">Performance</a></h3>
<table><thead><tr><th>10k phrases</th><th>Python</th><th>Rust</th></tr></thead><tbody>
<tr><td>Booting</td><td>4s</td><td>1s</td></tr>
<tr><td>Encoding</td><td>0.7s</td><td>0.3s</td></tr>
<tr><td>DL Inference</td><td>75s</td><td>75s</td></tr>
<tr><td>Total</td><td>80s</td><td>76s</td></tr>
<tr><td>Memory usage</td><td>1 GiB</td><td>0.7 GiB</td></tr>
</tbody></table>
<p>As DL inference is taking the majority of the time, Rust will only marginely improve performance.</p>
<p>This is an example of a bad use case for Rust as time is consumed in the C API which does not get affected by Rust.</p>
<p><em>You can check out the code for this specific job at:</em>  <a href="https://github.com/haixuanTao/bert-onnx-rs-pipeline"><em>https://github.com/haixuanTao/bert-onnx-rs-pipeline</em></a> </p>
<p><a href="https://github.com/haixuantao/bert-onnx-rs-pipeline"><img alt="github" src="https://img.shields.io/badge/bert--onnx--rs--pipeline-fff?labelColor=000&logo=github" height="20"></a>
<a href="https://github.com/haixuanTao/bert-onnx-rs-pipeline/"><img src="https://img.shields.io/github/stars/haixuanTao/bert-onnx-rs-pipeline?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="onnx-server-serving-bert-as-an-api"><a class="header" href="#onnx-server-serving-bert-as-an-api">ONNX Server: Serving BERT as an API</a></h2>
<p>Another use case is serving a BERT-like model as a server with a REST endpoint.</p>
<p>To see if Rust could be more performant than Python, I served the onnx model through <a href="https://actix.rs/">actix-web</a>, and to benchmark it, I made a clone in Python with <a href="https://fastapi.tiangolo.com/">FastAPI</a>.</p>
<h3 id="performance-3"><a class="header" href="#performance-3">Performance</a></h3>
<p>For a request of one phrase:</p>
<table><thead><tr><th></th><th>Python FastAPI</th><th>Rust Actix Web</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Encoding</td><td>400Œºs</td><td>100Œºs</td><td></td></tr>
<tr><td>ONNX Inference</td><td>~10ms</td><td>~10ms</td><td></td></tr>
<tr><td>API overhead</td><td>~2ms</td><td>~1ms</td><td></td></tr>
<tr><td>Mean Latency</td><td>12.8ms</td><td>10.4ms</td><td>-20%‚è∞</td></tr>
<tr><td>Requests/secs</td><td>77.5 #/s</td><td>95 #/s</td><td>+22%üî•</td></tr>
</tbody></table>
<p>The gain in performance comes from moving from considered ‚ÄúFast‚Äù Python library to Rust: </p>
<ul>
<li>FastAPI ‚è© Actix Web</li>
<li>BertokenizerFast Ô∏è‚è© Rust Tokenizer</li>
</ul>
<p>Thus, as Rust libraries tend to be faster than Python ones, Rust will be faster when the application is a composition of libraries.</p>
<p>That‚Äôs why, I can see Rust be a good fit for excessively performance centric applications such as Real-Time Deep Learning, Embedded Deep Learning, Large-Scale AI servers! ‚ù§Ô∏è‚Äçü¶Ä</p>
<p><em>Check the code:</em> <a href="https://github.com/haixuanTao/bert-onnx-rs-server"><em>https://github.com/haixuanTao/bert-onnx-rs-server</em></a><br />
<a href="https://github.com/haixuantao/bert-onnx-rs-server"><img alt="github" src="https://img.shields.io/badge/bert--onnx--rs--server-fff?labelColor=000&logo=github" height="20"></a>
<a href="https://github.com/haixuanTao/bert-onnx-rs-server/"><img src="https://img.shields.io/github/stars/haixuanTao/bert-onnx-rs-server?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="in-conclusion-should-you-use-rust-for-deep-learning"><a class="header" href="#in-conclusion-should-you-use-rust-for-deep-learning">In conclusion, should you use Rust for Deep Learning?</a></h2>
<ul>
<li>Like the whole Rust ecosystem, use it if you need performance Ô∏èand resilience!üöÄ But be aware that using Rust does not make things automatically fast!</li>
<li>If you need quick prototyping with a friendly language for Data Scientist, you should better use Python!</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pandas-vs-polars"><a class="header" href="#pandas-vs-polars">Pandas vs Polars</a></h1>
<p><a href="https://github.com/haixuantao/dataframe-python-rust"><img alt="github" src="https://img.shields.io/badge/dataframe--python--rust-fff?labelColor=000&logo=github" height="20"></a>
<a href="https://github.com/haixuanTao/dataframe-python-rust/"><img src="https://img.shields.io/github/stars/haixuanTao/dataframe-python-rust?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a></p>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>Everyone loves the API of Pandas. It‚Äôs fast, easy, and well documented. There are some rough edges, but most times, it‚Äôs just a blast.</p>
<p>Now, when it comes to production, Pandas is slightly trickier. Pandas does not scale very well‚Ä¶ there is no multithreading‚Ä¶ It‚Äôs not thread-safe‚Ä¶ It‚Äôs not memory efficient.</p>
<p>But all those problems are the raison d‚Äô√™tre of Rust.</p>
<p><strong>What if, there was a DataFrame API written in Rust that solves all those issues and at the same time keeps a nice API?</strong></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="polars"><a class="header" href="#polars">Polars</a></h2>
<p>Well, <a href="https://github.com/ritchie46/polars"><strong>Polars</strong></a> allows you to do read, write, filter, apply functions, group by and merge, all in a similar API as Pandas but in Rust.</p>
<p>It uses <a href="https://github.com/apache/arrow"><strong>Apache Arrow</strong></a>, a data framework purposely built for doing efficient data processing and data sharing across language.</p>
<h2 id="3-reasons-for-choosing-polars"><a class="header" href="#3-reasons-for-choosing-polars">3 reasons for choosing Polars</a></h2>
<h3 id="reason-1-performance"><a class="header" href="#reason-1-performance">Reason #1. Performance.</a></h3>
<p>it‚Äôs killing it <a href="https://h2oai.github.io/db-benchmark/">performance-wise</a>.</p>
<h3 id="reason-2-the-api-is-straightforward"><a class="header" href="#reason-2-the-api-is-straightforward">Reason #2. The API is straightforward.</a></h3>
<p>Do you want to mutate the data? Use <code>apply</code>. Do you want to filter the data? use <code>filter</code>. Do you want to merge? Use <code>join</code> . There is not going to be rust syntax like <code>struct</code>, <code>derive</code>, <code>impl</code> ‚Ä¶</p>
<h3 id="reason-3-no-troubles-with-the-borrow-checker"><a class="header" href="#reason-3-no-troubles-with-the-borrow-checker">Reason #3. No troubles with the borrow checker.</a></h3>
<p>It uses Arc-Mutex, which means that you can clone variables as much as you like. Variables are only references to in-memory data. No more fighting with the borrow checker. Mutability is limited to the API calls, which preserve the consistency/thread-safety of the data.</p>
<h2 id="3-caveats-of-polars"><a class="header" href="#3-caveats-of-polars">3 caveats of Polars</a></h2>
<h3 id="caveat-1-issues"><a class="header" href="#caveat-1-issues">‚Äå‚ÄåCaveat #1. Issues‚Ä¶</a></h3>
<p>Building a DataFrame API is hard. Pandas took 12 years to reach 1.0.0. And,  as Polars is rather young, you may face unexpected issues. In my cases, there were issues with <a href="https://github.com/ritchie46/polars/issues/387">\n characters</a>,<a href="https://github.com/ritchie46/polars/pull/399"> double quotes characters</a>, and <a href="https://github.com/ritchie46/polars/pull/400">long utf8</a>.</p>
<p>On the other hand, those are great first issues to get started with contribution and getting better at Rust üî®.</p>
<h3 id="caveat-2-getting-comfortable-with-two-apis-polars-and-arrow"><a class="header" href="#caveat-2-getting-comfortable-with-two-apis-polars-and-arrow">Caveat #2. Getting comfortable with two APIs: Polars and Arrow.</a></h3>
<p>As many of the heavy liftings are done using the Apache Arrow backend, you‚Äôll have to get used to reading the documentation of Polars but also Apache Arrow. Both documentations are pretty straightforward, but it might feel tiring for someone who was looking for a drop-in replacement of Pandas.</p>
<h3 id="caveat-3-compiling-time"><a class="header" href="#caveat-3-compiling-time">Caveat #3. Compiling time‚Ä¶</a></h3>
<p>Sadly, compiling time takes around <a href="https://github.com/ritchie46/polars/issues/402">3min</a> uncached. And, it uses a lot of resources.</p>
<h2 id="case-study"><a class="header" href="#case-study">Case Study</a></h2>
<p><strong>Now the question is, is it better than native Rust as I‚Äôve explained</strong> <a href="pandas-polars//01-pandas-vs-rust.html"><strong>in my previous blog post</strong></a><strong>?</strong></p>
<p>Let‚Äôs take a hands-on comparison for a Data Pipeline and get a feel for it.</p>
<p>In this case study, I‚Äôm going to use the <a href="https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/data?select=2012-07+Stack+Overflow.7z">stack overflow kaggle dataset</a>. I‚Äôm going to read the database, parse the dates, make a merge between the first tag and the<a href="https://en.wikipedia.org/wiki/Comparison_of_programming_languages#Failsafe_I/O_and_system_calls"> Wikipedia comparison of programming language</a>. Group by the status of the question asked. And retrieve the distribution of language‚Äôs features within each ‚Äòstatus‚Äô of questions.</p>
<p>We‚Äôll compare Polars API &amp; Native Rust generic heap structure to do this task.</p>
<ul>
<li><em>I‚Äôll go slightly quicker on the native Rust, as I already put more details</em> <a href="https://able.bio/haixuanTao/data-manipulation-pandas-vs-rust--1d70e7fc"><em>here</em></a><em>.</em></li>
<li><em>Multithreading is done on 12 threads Intel(R) Core(TM) i7-8750H / 20G RAM.</em></li>
<li><em>The database is 4.2G big for around 3.6 Million rows.</em></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="reading"><a class="header" href="#reading">Reading</a></h2>
<h3 id="reading-in-polars"><a class="header" href="#reading-in-polars">Reading in Polars</a></h3>
<p>Reading in Polars is pretty straightforward:</p>
<pre><code class="language-rust noplaypen">use polars::prelude::*;

//...

    let mut df = CsvReader::from_path(path)?
        .with_n_threads(Some(1)) // comment for multithreading
        .with_encoding(CsvEncoding::LossyUtf8)
        .has_header(true)
        .finish()?;
</code></pre>
<h3 id="reading-in-native-rust"><a class="header" href="#reading-in-native-rust">Reading in Native Rust</a></h3>
<p>Reading in Rust using <code>csv</code> and <code>serde</code> requires that you already have a <code>struct</code>, in my case my struct is <code>utils::NativeDataFrame</code></p>
<pre><code class="language-rust noplaypen">    let file = File::open(path)?;

    let mut rdr = csv::ReaderBuilder::new().delimiter(b',').from_reader(file);
    let mut records: Vec&lt;utils::NativeDataFrame&gt; = rdr
        .deserialize()
        .into_iter()
        .filter_map(|result| match result {
            Ok(rec) =&gt; rec,
            Err(e) =&gt; None,
        })
        .collect();
</code></pre>
<h3 id="performance-4"><a class="header" href="#performance-4">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>12 s</td><td>2.4x</td></tr>
<tr><td>Polars(Single thread)</td><td>19 s</td><td>1.5x</td></tr>
<tr><td><strong>Polars(Multithread)</strong></td><td><strong>6.6 s</strong></td><td><strong>4.5x</strong></td></tr>
<tr><td>Pandas</td><td>29.6 s</td><td></td></tr>
</tbody></table>
<p>For reading, <strong>Polars</strong> is faster than Pandas and Native Rust, being able to do it in multithreading.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="apply"><a class="header" href="#apply">Apply</a></h2>
<h3 id="applying-function-in-polars"><a class="header" href="#applying-function-in-polars">Applying Function in Polars</a></h3>
<p>To Apply a function in Polars, you can use the default <code>apply</code> or <code>may_apply</code>. I prefer the latter. </p>
<pre><code class="language-rust noplaypen">fn str_to_date(dates: &amp;Series) -&gt; std::result::Result&lt;Series, PolarsError&gt; {
    let fmt = Some(&quot;%m/%d/%Y %H:%M:%S&quot;);

    Ok(dates.utf8()?.as_date64(fmt)?.into_series())
}

fn count_words(dates: &amp;Series) -&gt; std::result::Result&lt;Series, PolarsError&gt; {
    Ok(dates
	.utf8()?
	.into_iter()
	.map(|opt_name: Option&lt;&amp;str&gt;| 
		 opt_name.map(|name: &amp;str| name.split(&quot; &quot;).count() as u64
	))
	.collect::&lt;UInt64Chunked&gt;()
	.into_series())
}

// ...

    // Apply Format Date
    df.may_apply(&quot;PostCreationDate&quot;, str_to_date)?;

    let t_formatting = Instant::now();

    // Apply Custom counting words in string
    df.may_apply(&quot;BodyMarkdown&quot;, count_words)?;
</code></pre>
<p>Note that parallel apply is not yet implemented for utf8 series.</p>
<h3 id="applying-function-in-native-rust"><a class="header" href="#applying-function-in-native-rust">Applying Function in Native Rust</a></h3>
<p>What I like about native rust mutation, is that the syntax is standard among iterator, and so once you get comfortable with the syntax, you can apply it everywhere üòÄ</p>
<pre><code class="language-rust noplaypen">use chrono::{DateTime, NaiveDate, NaiveDateTime, NaiveTime};
// use rayon::prelude::*;  for multithreads

    // Apply Format Date
    let fmt = &quot;%m/%d/%Y %H:%M:%S&quot;;

    records
	.iter_mut()  // .par_iter_mut() for multithreads
	.for_each(|record: &amp;mut utils::NativeDataFrame| {
	    record.PostCreationDatetime =
		match DateTime::parse_from_str(
		  record.PostCreationDate.as_ref().unwrap(), fmt) {
		    Ok(dates) =&gt; Some(dates),
		    Err(_) =&gt; None,
		}
	});

    // Apply Custom Formatting counting words in string
    records
	.iter_mut() // .par_iter_mut() for multithreads
	.for_each(|record: &amp;mut utils::NativeDataFrame| {
	    record.CountWords =
		Some(
	  record.BodyMarkdown.as_ref().unwrap().split(' ').count() as f64
		)
	});
</code></pre>
<h3 id="performance-for-formatting-dates"><a class="header" href="#performance-for-formatting-dates">Performance for formatting dates</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>.98 s</td><td>8x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>.148 s</strong></td><td><strong>52x</strong></td></tr>
<tr><td>Polars(Single thread)</td><td>.88 s</td><td>8.8x</td></tr>
<tr><td>Pandas</td><td>7.8 s</td><td></td></tr>
</tbody></table>
<h3 id="performance-for-counting-words"><a class="header" href="#performance-for-counting-words">Performance for counting words</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>9 s</td><td>2.7x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>1.3 s</strong></td><td><strong>19x</strong></td></tr>
<tr><td>Polars(Single thread)</td><td>9 s</td><td>2.7x</td></tr>
<tr><td>Pandas</td><td>24.8 s</td><td></td></tr>
</tbody></table>
<p><strong>Polars</strong> does not seem to offer increased performance over the standard library on a single thread, and I couldn‚Äôt find a way to do multi-threaded apply‚Ä¶ In this scenario, I‚Äôll prefer <strong>native Rust</strong>.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="merging"><a class="header" href="#merging">Merging</a></h2>
<h3 id="merging-in-polars"><a class="header" href="#merging-in-polars">Merging in Polars</a></h3>
<p>Merging in Polars is dead easy, although the number of strategy for filling <code>none</code> values are limited for now.</p>
<pre><code class="language-rust noplaypen">    df = df
        .join(&amp;df_wikipedia, &quot;Tag1&quot;, &quot;Language&quot;, JoinType::Left)?
        .fill_none(FillNoneStrategy::Min)?;
</code></pre>
<h3 id="merging-in-native-rust"><a class="header" href="#merging-in-native-rust">Merging in Native Rust</a></h3>
<p>Merging in native Rust can be done with nested structure and pairing with a Hashmap:</p>
<pre><code class="language-rust noplaypen">let mut hash_wikipedia: &amp;HashMap&lt;&amp;String, &amp;utils::WikiDataFrame&gt; = &amp;records_wikipedia
    .iter()
    .map(|record| (record.Language.as_ref().unwrap(), record))
    .collect();

records.iter_mut().for_each(|record| {
    record.Wikipedia = match hash_wikipedia.get(&amp;record.Tag1.as_ref().unwrap()) {
        Some(wikipedia) =&gt; Some(wikipedia.clone().clone()),
        None =&gt; None,
    }
});
</code></pre>
<h3 id="performance-5"><a class="header" href="#performance-5">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>.680 s</td><td>6.3x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>.215 s</strong></td><td><strong>20x</strong></td></tr>
<tr><td>Polars</td><td>.543 s</td><td>8x</td></tr>
<tr><td>Pandas</td><td>4.347 s</td><td></td></tr>
</tbody></table>
<p>For merging, having a nested structure with <code>None</code> values can be very verbose. So, I‚Äôll recommend using <strong>Polars</strong> for merging.</p>
<p><em>I‚Äôm not sure If polars merging is done multi-threaded or not. It seems to be multithreaded by default.</em></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="groupby"><a class="header" href="#groupby">Groupby</a></h2>
<h3 id="group-by-in-polars"><a class="header" href="#group-by-in-polars">Group By in Polars</a></h3>
<p>Group by in polars are pretty easy.</p>
<pre><code class="language-rust noplaypen">    // Groupby series as a clone of reference
    let groupby_series = vec![
        df.column(&quot;OpenStatus&quot;)?.clone(),
    ];

    let target_column = vec![
        &quot;ReputationAtPostCreation&quot;,
        &quot;OwnerUndeletedAnswerCountAtPostTime&quot;,
        &quot;Imperative&quot;,
        &quot;Object-oriented&quot;,
        &quot;Functional&quot;,
        &quot;Procedural&quot;,
        &quot;Generic&quot;,
        &quot;Reflective&quot;,
        &quot;Event-driven&quot;,
    ];

    let groups = df
        .groupby_with_series(groupby_series, false)?
        .select(target_column)
        .mean()?;
</code></pre>
<h3 id="group-by-in-native-rust"><a class="header" href="#group-by-in-native-rust">Group By in Native Rust</a></h3>
<p>However, it is quite tricky in native Rust. To make a group by in a thread-safe manner, you‚Äôll need to use a Hashmap with the <code>fold</code> method. Note that, <a href="https://docs.rs/rayon/0.7.1/rayon/iter/trait.ParallelIterator.html#method.fold">parallel folds</a> are slightly more complicated as folding requires passing data around threads.</p>
<pre><code class="language-rust noplaypen">    let groups_hash: HashMap&lt;String, (utils::GroupBy, i16)&gt; = records
        .iter() // .par_iter()
        .fold(
            HashMap::new(), // || HashMap::new()
            |mut hash_group: HashMap&lt;String, (utils::GroupBy, i16)&gt;, record| {
                let group: utils::GroupBy = if let Some(wiki) = &amp;record.Wikipedia {
                    utils::GroupBy {
                        status: record.OpenStatus.as_ref().unwrap().to_string(),
                        ReputationAtPostCreation: record.ReputationAtPostCreation.unwrap(),
                        OwnerUndeletedAnswerCountAtPostTime: record
                            .OwnerUndeletedAnswerCountAtPostTime
                            .unwrap(),
                        Imperative: wiki.Imperative.unwrap(),
                        ObjectOriented: wiki.ObjectOriented.unwrap(),
                        Functional: wiki.Functional.unwrap(),
                        Procedural: wiki.Procedural.unwrap(),
                        Generic: wiki.Generic.unwrap(),
                        Reflective: wiki.Reflective.unwrap(),
                        EventDriven: wiki.EventDriven.unwrap(),
                    }
                } else {
                    utils::GroupBy {
                        status: record.OpenStatus.as_ref().unwrap().to_string(),
                        ReputationAtPostCreation: record.ReputationAtPostCreation.unwrap(),
                        OwnerUndeletedAnswerCountAtPostTime: record
                            .OwnerUndeletedAnswerCountAtPostTime
                            .unwrap(),
                        ..Default::default()
                    }
                };
                if let Some((previous, count)) = hash_group.get_mut(&amp;group.status.to_string()) {
                    *previous = previous.clone() + group;
                    *count += 1;
                } else {
                    hash_group.insert(group.status.to_string(), (group, 1));
                };
                hash_group
            },
        ); // }
           // .reduce(
           //     || HashMap::new(),
           //     |prev, other| {
           //         let set1: HashSet&lt;String&gt; = prev.keys().cloned().collect();
           //         let set2: HashSet&lt;String&gt; = other.keys().cloned().collect();
           //         let unions: HashSet&lt;String&gt; = set1.union(&amp;set2).cloned().collect();
           //         let mut map = HashMap::new();
           //         for key in unions.iter() {
           //             map.insert(
           //                 key.to_string(),
           //                 match (prev.get(key), other.get(key)) {
           //                     (Some((previous, count_prev)), Some((group, count_other))) =&gt; {
           //                         (previous.clone() + group.clone(), count_prev + count_other)
           //                     }
           //                     (Some(previous), None) =&gt; previous.clone(),
           //                     (None, Some(other)) =&gt; other.clone(),
           //                     (None, None) =&gt; (utils::GroupBy::new(), 0),
           //                 },
           //             );
           //         }
           //         map
           //     },
           // );

    let groups: Vec&lt;utils::GroupBy&gt; = groups_hash
        .iter()
        .map(|(_, (group, count))| utils::GroupBy {
            status: group.status.to_string(),
            ReputationAtPostCreation: group.ReputationAtPostCreation / count.clone() as f64,
            OwnerUndeletedAnswerCountAtPostTime: group.OwnerUndeletedAnswerCountAtPostTime
                / count.clone() as f64,
            Imperative: group.Imperative / count.clone() as f64,
            ObjectOriented: group.ObjectOriented / count.clone() as f64,
            Functional: group.Functional / count.clone() as f64,
            Procedural: group.Procedural / count.clone() as f64,
            Generic: group.Generic / count.clone() as f64,
            Reflective: group.Reflective / count.clone() as f64,
            EventDriven: group.EventDriven / count.clone() as f64,
        })
        .collect();
</code></pre>
<p><em>Uncomment for multithreading</em></p>
<h3 id="performance-6"><a class="header" href="#performance-6">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>.536 s</td><td>2x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>.115 s</strong></td><td><strong>9.5x</strong></td></tr>
<tr><td>Polars(Single thread)</td><td>.131 s</td><td>8.3x</td></tr>
<tr><td>Polars(Multithread)</td><td>.125 s</td><td>8.8x</td></tr>
<tr><td>Pandas</td><td>1.1 s</td><td></td></tr>
</tbody></table>
<p>Group By and Merging are the ideal case for <strong>Polars</strong>. You‚Äôll get 8x more performance than Pandas on a single thread, and Polars handles multithreading, although in my case, it didn‚Äôt matter much.</p>
<p>Native Rust can do it as well, but judging by the size of the code, it is not an ideal use case.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<h3 id="performance-overall"><a class="header" href="#performance-overall">Performance overall</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>24 s</td><td>3.3x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>13.7 s</strong></td><td><strong>5.8x</strong></td></tr>
<tr><td>Polars (Single thread)</td><td>30 s</td><td>2.6x</td></tr>
<tr><td>Polars (Multithread)</td><td>17 s</td><td>4.7x</td></tr>
<tr><td>Polars (lazy, Multithreaded)</td><td>16.5 s</td><td>4.8x</td></tr>
<tr><td>Pandas</td><td>80 s</td><td></td></tr>
</tbody></table>
<p>As reading is IO bound, I wanted to make a benchmark of pure performance.</p>
<h3 id="performance-without-reading"><a class="header" href="#performance-without-reading">Performance without Reading</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>12 s</td><td>3.3x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>1.7 s</strong></td><td><strong>23x</strong></td></tr>
<tr><td>Polars (Single thread)</td><td>10 s</td><td>4x</td></tr>
<tr><td>Polars (Multithread)</td><td>11 s</td><td>3.6x</td></tr>
<tr><td>Polars (Lazy, Multithread)</td><td>11 s</td><td>3.6x</td></tr>
<tr><td>Pandas</td><td>40 s</td><td></td></tr>
</tbody></table>
<p>‚Äå</p>
<h3 id="overall-takeaway"><a class="header" href="#overall-takeaway">Overall takeaway</a></h3>
<ul>
<li>Use Polars if you want a great API.</li>
<li>Use Polars for merging and group by.</li>
<li>Use Polars for <a href="https://en.wikipedia.org/wiki/SIMD">single instruction multiple data(SIMD) </a>operation.</li>
<li>Use Native Rust if you‚Äôre already familiar with rust generic heap structure like vectors and hashmap.</li>
<li>Use Native Rust for linear mutation of the data with <code>map</code> and <code>fold</code>. You‚Äôll get O(n) scalability that can be parallelized almost instantly with <code>rayon</code>.</li>
<li>Use pandas when performance, scalability, memory usage does not matter.</li>
</ul>
<p>For me, both Polars and native Rust makes a lot of sense for data between 1Go and 1To.</p>
<p>I‚Äôll invite you to make your own opinion. The code is available here: <a href="https://github.com/haixuanTao/dataframe-python-rust">https://github.com/haixuanTao/dataframe-python-rust</a></p>
<p><a href="https://github.com/haixuantao/dataframe-python-rust"><img alt="github" src="https://img.shields.io/badge/dataframe--python--rust-fff?labelColor=000&logo=github" height="20"></a>
<a href="https://github.com/haixuanTao/dataframe-python-rust/"><img src="https://img.shields.io/github/stars/haixuanTao/dataframe-python-rust?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pandas-vs-rust-1-google-result"><a class="header" href="#pandas-vs-rust-1-google-result">Pandas vs Rust (#1 Google Result)</a></h1>
<p><a href="https://github.com/haixuantao/Data-Manipulation-Rust-Pandas"><img alt="github" src="https://img.shields.io/badge/Data--Manipulation--Rust--Pandas-fff?labelColor=000&logo=github" height="20"></a>
<a href="https://github.com/haixuanTao/Data-Manipulation-Rust-Pandas/"><img src="https://img.shields.io/github/stars/haixuanTao/Data-Manipulation-Rust-Pandas?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a></p>
<h2 id="introduction-2"><a class="header" href="#introduction-2">Introduction</a></h2>
<p>Pandas is the main Data analysis package of Python. For many reasons, Native Python has poor performance on data analysis without vectorization with NumPy and the likes. And historically, Pandas has been created by Wes McKinney to package those optimisations in a nice API to facilitate data analysis in Python.</p>
<p>This, however, is not necessary for Rust. Rust has great data performance natively. This is why Rust doesn‚Äôt really need a package like Pandas.</p>
<p>I believe the rustiest way to do Data Manipulation in Rust would be to build a <strong>heap of data struct</strong>.</p>
<p>This is my experience and reasoning comparing <strong>Pandas vs Rust</strong>.</p>
<h3 id="data"><a class="header" href="#data">Data</a></h3>
<p>Performance benchmarks are done on this very random dataset: <a href="https://www.kaggle.com/START-UMD/gtd">https://www.kaggle.com/START-UMD/gtd</a> that offers around 160,000 lines / 130 columns for a total size of 150Mb. The size of this dataset corresponds to the type of dataset I regularly encounter, that‚Äôs why I chose this one. It isn‚Äôt the biggest dataset in the world, and, more studies should probably be done on a larger dataset.</p>
<p>The merge will be done with another random dataset: <a href="https://datacatalog.worldbank.org/dataset/world-development-indicators">https://datacatalog.worldbank.org/dataset/world-development-indicators</a>, the <code>WDICountry.csv</code></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="reading-1"><a class="header" href="#reading-1">Reading</a></h2>
<h3 id="pandas"><a class="header" href="#pandas">Pandas</a></h3>
<p>Reading and instantiating Data in Pandas is pretty straightforward, and handles by default many data quality problems:</p>
<pre><code class="language-python">import pandas as pd

path = &quot;/home/peter/Documents/TEST/RUST/terrorism/src/globalterrorismdb_0718dist.csv&quot;
df = pd.read_csv(path)
</code></pre>
<h3 id="rust-reading-csv"><a class="header" href="#rust-reading-csv">Rust Reading CSV</a></h3>
<p>For Rust, Managing bad quality data is very very tedious. In this dataset, some fields are empty, some lines are badly formatted, and some are not UTF-8 encoded.</p>
<p>To open the CSV, I used the <code>csv</code> crate but it does not solve all the issues listed above. With well-formatted data, reading can be done like so:</p>
<pre><code class="language-rust noplaypen">let path = &quot;/home/peter/Documents/TEST/RUST/terrorism/src/foo.csv&quot;;
let mut rdr = csv::Reader::from_path(path).unwrap();
</code></pre>
<p>But with bad quality formatting, I had to add additional parameters like:</p>
<pre><code class="language-rust noplaypen">use std::fs::File;    
use encoding_rs::WINDOWS_1252;
use encoding_rs_io::DecodeReaderBytesBuilder;

// ...

    let file = File::open(path)?;
    let transcoded = DecodeReaderBytesBuilder::new()
        .encoding(Some(WINDOWS_1252))
        .build(file);
    let mut rdr = csv::ReaderBuilder::new()
        .delimiter(b',')
        .from_reader(transcoded); 
</code></pre>
<p><em>ref:</em> <a href="https://stackoverflow.com/questions/53826986/how-to-read-a-non-utf8-encoded-csv-file"><em>https://stackoverflow.com/questions/53826986/how-to-read-a-non-utf8-encoded-csv-file</em></a></p>
<h3 id="rust-instantiating-the-data"><a class="header" href="#rust-instantiating-the-data">Rust Instantiating the data</a></h3>
<p>To instantiate the data, I used Serde <a href="https://serde.rs/">https://serde.rs/</a> for serializing and deserializing my data.</p>
<p>To use Serde, I needed to make a struct of my data. Having a struct of my data is great as it makes my code follow a model-based coding paradigm with a well-defined type for each field. It also enables me to implement traits and methods on top of them.</p>
<p>However, the data I wanted to use has 130 columns‚Ä¶ And, It seemed that there is no way to generate the definition of the struct automatically.</p>
<p>To avoid doing the definition manually, I had to build my own struct generator:</p>
<pre><code class="language-rust noplaypen">
fn inspect(path: &amp;str) {
    let mut record: Record = HashMap::new();

    let mut rdr = csv::Reader::from_path(path).unwrap();

    for result in rdr.deserialize() {
        match result {
            Ok(rec) =&gt; {
                record = rec;
                break;
            }
            Err(e) =&gt; (),
        };
    }
    // Print Struct
    println!(&quot;#[skip_serializing_none]&quot;);
    println!(&quot;#[derive(Debug, Deserialize, Serialize)]&quot;);
    println!(&quot;struct DataFrame {{&quot;);
    for (key, value) in &amp;record {
        println!(&quot;    #[serialize_always]&quot;);

        match value.parse::&lt;i64&gt;() {
            Ok(n) =&gt; {
                println!(&quot;    {}: Option&lt;i64&gt;,&quot;, key);
                continue;
            }
            Err(e) =&gt; (),
        }
        match value.parse::&lt;f64&gt;() {
            Ok(n) =&gt; {
                println!(&quot;    {}: Option&lt;f64&gt;,&quot;, key);
                continue;
            }
            Err(e) =&gt; (),
        }
        println!(&quot;    {}: Option&lt;String&gt;,&quot;, key);
    }
    println!(&quot;}}&quot;);
}
</code></pre>
<p>This generated the struct as follows:</p>
<pre><code class="language-rust noplaypen">use serde::{Deserialize, Serialize};
use serde_with::skip_serializing_none;

#[skip_serializing_none]
#[derive(Debug, Clone, Deserialize, Serialize)]
struct DataFrame {
    #[serialize_always]
    individual: Option&lt;f64&gt;,
    #[serialize_always]
    natlty3_txt: Option&lt;String&gt;,
    #[serialize_always]
    ransom: Option&lt;f64&gt;,
    #[serialize_always]
    related: Option&lt;String&gt;,
    #[serialize_always]
    gsubname: Option&lt;String&gt;,
    #[serialize_always]
    claim2: Option&lt;String&gt;,
    #[serialize_always]

    // ...
</code></pre>
<p><em>skip_serializing_none: Avoid having error on empty fields in the CSV.</em></p>
<p><em>serialize_always: Makes the number of field when writing csv fixed.</em></p>
<p>Now, that I had my struct, I used serde serialization to populate a vector of struct:</p>
<pre><code class="language-rust noplaypen">    let mut records: Vec&lt;DataFrame&gt; = Vec::new();

    for result in rdr.deserialize() {
        match result {
            Ok(rec) =&gt; {
                records.push(rec);
            }
            Err(e) =&gt; println!(&quot;{}&quot;, e),
        };
    }
</code></pre>
<p>This generated my vector of struct, hooray üéâ</p>
<p>On a general note with Rust, you shouldn‚Äôt expect things to work as smoothly as it would with Python.</p>
<p>On reading / instantiating data, <strong>Pandas</strong> wins hands down for CSV.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="filtering"><a class="header" href="#filtering">Filtering</a></h2>
<h3 id="pandas-1"><a class="header" href="#pandas-1">Pandas</a></h3>
<p>There are many ways to do filtering in pandas, the most common way for me is as follows:</p>
<pre><code class="language-python">df = df[df.country_txt == &quot;United States&quot;]
df.to_csv(&quot;python_output.csv&quot;)
</code></pre>
<h3 id="rust"><a class="header" href="#rust">Rust</a></h3>
<p>To do filtering in Rust, we can refer to the docs for vector in Rust <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html">https://doc.rust-lang.org/std/vec/struct.Vec.html</a></p>
<p>There is a large umbrella of methods for Vector filtering, with many nightly features that are going to be great for data manipulation when they ship. For this use case, I used the <code>retain</code> method as it fitted my need perfectly:</p>
<pre><code class="language-rust noplaypen">    records.retain(|x| &amp;x.country_txt.unwrap() == &quot;United States&quot;);
    let mut wtr =
        csv::Writer::from_path(&quot;output_rust_filter.csv&quot;)?;

    for record in &amp;records {
        wtr.serialize(record)?;
    }
</code></pre>
<p><strong>One big difference between Pandas and Rust is that Rust filtering uses Closures (<em>eq. lambda function in python</em>) whereas Pandas filtering uses Pandas API based on columns. Rust can therefore make more complex filters compared to Pandas. It also adds in readability.</strong></p>
<h3 id="performance-7"><a class="header" href="#performance-7">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Mem Usage(Gb)</th></tr></thead><tbody>
<tr><td>Pandas</td><td>3.0s</td><td>2.5Gb</td></tr>
<tr><td><strong>Rust</strong></td><td><strong>1.6s üî• -50%</strong></td><td><strong>1.7Gb üî• -32%</strong></td></tr>
</tbody></table>
<p>Even though we‚Äôre using Pandas API for filtering, we get significantly better performance using Rust.</p>
<p>On Filtering, <strong>Rust</strong> seems to be more capable and faster. üöÖ</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="groupby-1"><a class="header" href="#groupby-1">Groupby</a></h2>
<h3 id="pandas-2"><a class="header" href="#pandas-2">Pandas</a></h3>
<p>Group by are a big part of the data reduction pipeline in python, it goes usually as follows:</p>
<pre><code class="language-python">df = df.groupby(by=&quot;country_txt&quot;, as_index=False).agg(
    {&quot;nkill&quot;: &quot;sum&quot;, &quot;individual&quot;: &quot;mean&quot;, &quot;eventid&quot;: &quot;count&quot;}
)
df.to_csv(&quot;python_output_groupby.csv&quot;)
</code></pre>
<h3 id="rust-1"><a class="header" href="#rust-1">Rust</a></h3>
<p>For group by and data reduction, thanks to <a href="https://able.bio/insideoutclub">David Sanders</a>, group by can be done as follows:</p>
<pre><code class="language-rust noplaypen">use itertools::Itertools;


// ...

#[derive(Debug, Deserialize, Serialize)]
struct GroupBy {
    country: String,
    total_nkill: f64,
    average_individual: f64,
    count: f64,
}

// ... 

    let groups = records
        .into_iter()
        .sorted_unstable_by(|a, b| Ord::cmp(&amp;a.country_txt, &amp;b.country_txt))
        .group_by(|record| record.country_txt.clone())
        .into_iter()
        .map(|(country, group)| {
            let (total_nkill, count, average_individual) = group.into_iter().fold(
                (0., 0., 0.),
                |(total_nkill, count, average_individual), record| {
                    (
                        total_nkill + record.nkill.unwrap_or(0.),
                        count + 1.,
                        average_individual + record.individual.unwrap_or(0.),
                    )
                },
            );
            GroupBy {
                country: country.unwrap(),
                total_nkill,
                average_individual: average_individual / count,
                count,
            }
        })
        .collect::&lt;Vec&lt;_&gt;&gt;();
    let mut wtr =
        csv::Writer::from_path(&quot;output_rust_groupby.csv&quot;)
            .unwrap();

    for group in &amp;groups {
        wtr.serialize(group)?;
    }
</code></pre>
<p>‚Äå</p>
<p>Although this solution is not as elegant as Pandas groupby, it gives a lot of flexibility on the computation of the reduced fields. Again, thanks to Closures.</p>
<p>I think more reduction method other than <code>sum</code> and <code>fold</code> would greatly improve the development experience of map-reduce style operation in rust. We will then probably have equivalent experience between Rust and Pandas.</p>
<h3 id="performance-8"><a class="header" href="#performance-8">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Mem(Gb)</th></tr></thead><tbody>
<tr><td>Pandas</td><td>2.78s</td><td>2.5Gb</td></tr>
<tr><td><strong>Rust</strong></td><td><strong>2.0süî• -35%</strong></td><td><strong>1.7Gbüî• -32%</strong></td></tr>
</tbody></table>
<p>Although the performance is better for Rust, I would advise using <strong>Pandas</strong> for map-reduce heavy application, as it seems more appropriate.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="mutation"><a class="header" href="#mutation">Mutation</a></h2>
<h3 id="pandas-3"><a class="header" href="#pandas-3">Pandas</a></h3>
<p>There are many ways to do mutation in Pandas, I usually do the following for performance and functional style:</p>
<pre><code class="language-python">df[&quot;computed&quot;] = df[&quot;nkill&quot;].map(lambda x: (x - 10) / 2 + x ** 2 / 3)
df.to_csv(&quot;python_output_map.csv&quot;)
</code></pre>
<h3 id="rust-2"><a class="header" href="#rust-2">Rust</a></h3>
<p>For mutation, the functional <code>iter</code> of Rust really makes this part a walk in the park:</p>
<pre><code class="language-rust noplaypen">    records.iter_mut().for_each(|x: &amp;mut DataFrame| {
        let nkill = match &amp;x.nkill {
            Some(nkill) =&gt; nkill,
            None =&gt; &amp;0.,
        };

        x.computed = Some((nkill - 10.) / 2. + nkill * nkill / 3.);
    });

    let mut wtr = csv::Writer::from_path(
        &quot;output_rust_map.csv&quot;,
    )?;
    for record in &amp;records {
        wtr.serialize(record)?;
    }
</code></pre>
<h3 id="performance-9"><a class="header" href="#performance-9">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Mem(Gb)</th></tr></thead><tbody>
<tr><td>Pandas</td><td>12.82s</td><td>4.7Gb</td></tr>
<tr><td><strong>Rust</strong></td><td><strong>1.58süî• -87%</strong></td><td><strong>1.7Gbüî• -64%</strong></td></tr>
</tbody></table>
<p>This is where the difference really appeared to me. Pandas do not scale for line-by-line lambda functions. Pandas would have been even worst if I had done an operation involving several columns.</p>
<p><strong>Rust</strong> is way better for line-by-line mutation natively.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="merging-1"><a class="header" href="#merging-1">Merging</a></h2>
<h3 id="python"><a class="header" href="#python">Python</a></h3>
<p>Merging in python is pretty efficient generally speaking, it goes like this in general:</p>
<pre><code class="language-python">df_country = pd.read_csv(
    &quot;/home/peter/Documents/TEST/RUST/terrorism/src/WDICountry.csv&quot;
)

df_merge = pd.merge(
    df, df_country, left_on=&quot;country_txt&quot;, right_on=&quot;Short_Name&quot;
)
df_merge.to_csv(&quot;python_output_merge.csv&quot;)
</code></pre>
<h3 id="rust-3"><a class="header" href="#rust-3">Rust</a></h3>
<p>For Rust, however, this is a tricky part as, with Struct, merging isn‚Äôt really a thing. For me, the rustiest way of doing a merge is by adding a nested field containing the other struct we want to join data with.</p>
<p>I  first created a new struct and a new heap for the new data:</p>
<pre><code class="language-rust noplaypen">#[skip_serializing_none]
#[derive(Clone, Debug, Deserialize, Serialize)]
struct DataFrameCountry {
    #[serialize_always]
    SNA_price_valuation: Option&lt;String&gt;,
    #[serialize_always]
    IMF_data_dissemination_standard: Option&lt;String&gt;,
    #[serialize_always]
    Latest_industrial_data: Option&lt;String&gt;,
    #[serialize_always]
    System_of_National_Accounts: Option&lt;String&gt;,
    //...

// ...

    let mut records_country: Vec&lt;DataFrameCountry&gt; = Vec::new();
    let file = File::open(path_country)?;
    let transcoded = DecodeReaderBytesBuilder::new()
        .encoding(Some(WINDOWS_1252))
        .build(file);
    let mut rdr = csv::ReaderBuilder::new()
        .delimiter(b',')
        .from_reader(transcoded); 

    for result in rdr.deserialize() {
        match result {
            Ok(rec) =&gt; {
                records_country.push(rec);
            }
            Err(e) =&gt; println!(&quot;{}&quot;, e),
        };
    }
</code></pre>
<p>I then cloned this new struct with the previous struct on a specific field that is unique.</p>
<pre><code class="language-rust noplaypen">
impl DataFrame {
    fn add_country_ext(&amp;mut self, country: Option&lt;DataFrameCountry&gt;) {
        self.country_merge = Some(country)
    }
}

//...

    for country in records_country {
        records
            .iter_mut()
            .filter(|record| record.country_txt == country.Short_Name)
            .for_each(|x| {
                x.add_country_ext(Some(country.clone()));
            });
    }
    let mut wtr =
        csv::Writer::from_path(&quot;output_rust_join.csv&quot;)
            .unwrap();
    for record in &amp;records {
        wtr.serialize(record)?;
    }
</code></pre>
<p>I cloned the data for convenience and also for better comparability, but a reference can be passed if you can manage it.</p>
<p>And there we go! üöÄ</p>
<p>Except, a nested struct is not yet serializable in CSV for Rust -&gt; <a href="https://github.com/BurntSushi/rust-csv/pull/197">https://github.com/BurntSushi/rust-csv/pull/197</a></p>
<p>So I had to adapt it to:</p>
<pre><code class="language-rust noplaypen">impl DataFrame {
    fn add_country_ext(&amp;mut self, country: Option&lt;DataFrameCountry&gt;) {
        self.country_ext = Some(format!(&quot;{:?}&quot;, country))
    }
}
</code></pre>
<p>But, then, we got a sort of merge! üöÄ</p>
<h3 id="performance-10"><a class="header" href="#performance-10">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Mem(Gb)</th></tr></thead><tbody>
<tr><td>Pandas</td><td>22.47s</td><td>11.8Gb</td></tr>
<tr><td><strong>Rust</strong></td><td><strong>5.48süî• -75%</strong></td><td><strong>2.6Gbüî• -78%</strong></td></tr>
</tbody></table>
<p><strong>Rust</strong> is capable of doing nested structs that are going to be as capable if not more capable than <strong>Pandas</strong> merges. However, it isn‚Äôt really a one to one comparison and in this case, it is going to depend on your use case.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h2>
<p>After this experience, this is my take away.</p>
<ul>
<li>Use Pandas when you can: small CSV(&lt;1M lines), simple operation, data cleaning ‚Ä¶</li>
<li>Use Rust when you have: complex operations, memory heavy or time-consuming pipelines, custom functions, scalable software‚Ä¶</li>
</ul>
<p>That been said, Rust offers impressive flexibility compared to Pandas. Adding the fact that Rust is way more capable of multi-threading than Pandas, I believe that Rust can solve problems Pandas simply cannot.</p>
<p>Additionally, the possibility to run Rust on any platform(Web, Android, or Embedded) also create new opportunities for data manipulation in places inconceivable for Pandas and can provide solutions for yet to be resolved challenges.</p>
<h3 id="performance-11"><a class="header" href="#performance-11">Performance</a></h3>
<p>The performance table gives us an insight as to what to expect from Rust. I believe, the speedup can go from <strong>x2</strong> at the minimum and up to <strong>x50</strong> for large data pipelines. The memory use will have an even greater decrease as memory usage accumulates over time with python.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scraping-python-vs-rust"><a class="header" href="#scraping-python-vs-rust">Scraping Python vs Rust</a></h1>
<h2 id="introduction-3"><a class="header" href="#introduction-3">Introduction</a></h2>
<p>Web scraping is about as error-prone as you can imagine. Pages might not exist, HTML elements might not always be there‚Ä¶ And so, a language that can support errors and edge cases well at runtime and not crash is a huge plus.</p>
<h2 id="performance-12"><a class="header" href="#performance-12">Performance</a></h2>
<p>Performance test of scraping the 50 pages of <a href="http://books.toscrape.com/catalogue/page-2.html">http://books.toscrape.com/catalogue/page-1.html</a></p>
<table><thead><tr><th>Name</th><th>CPU Usage</th><th>Time(s)</th></tr></thead><tbody>
<tr><td>Synchronous Python</td><td>5%</td><td>44.3s</td></tr>
<tr><td>Synchronous Rust</td><td>7%</td><td>55s</td></tr>
<tr><td>Async Python</td><td>63%</td><td>2.5s</td></tr>
<tr><td>Async Rust</td><td>107%</td><td>2.25s</td></tr>
</tbody></table>
<p>‚Äå
Performances are pretty similar for such low level of requests. Time is consumed downloading. Maybe with significantly more requests, bigger difference would be seen.</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="synchronous-python-code"><a class="header" href="#synchronous-python-code">Synchronous Python code</a></h3>
<pre><code class="language-python">import requests
import bs4 as bs
import csv
URL = &quot;http://books.toscrape.com/catalogue/page-%d.html&quot;

with open('./test_python.csv', 'w') as csvfile:
    spamwriter = csv.writer(csvfile, delimiter=',')
    for i in range(1, 50):
        response = requests.get(URL % i)
        if response.status_code == 200:
            content = response.content
            soup = bs.BeautifulSoup(content, 'lxml')
            articles = soup.find_all('article')

            for article in articles:
                information = []
                information.append(article.find(
                    'p', class_='price_color').text)
                information.append(article.find('h3').find('a').get('title'))
                spamwriter.writerow(information)
</code></pre>
<p>‚Äå</p>
<h3 id="synchronous-rust-code"><a class="header" href="#synchronous-rust-code">Synchronous Rust code:</a></h3>
<pre><pre class="playground"><code class="language-rust noplaygen edition2018">use csv::Writer;
use select::document::Document;
use select::predicate::{Attr, Class, Name};
use std::fs::OpenOptions;

async fn test(i: &amp;i32) -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    let url = format!(&quot;http://books.toscrape.com/catalogue/page-{}.html&quot;, i);
    let response = reqwest::get(&amp;url).await?.text().await?;
    let file = OpenOptions::new()
        .write(true)
        .create(true)
        .append(true)
        .open(&quot;test2.csv&quot;)
        .unwrap();
    let mut wtr = Writer::from_writer(file);

    let document = Document::from(response.as_str());

    for node in document.find(Name(&quot;article&quot;)) {
        let name = match node.find(Name(&quot;h3&quot;)).next() {
            Some(h3) =&gt; h3.find(Name(&quot;a&quot;)).next().unwrap().text(),
            None =&gt; &quot;&quot;.to_string(),
        };
        let price = node
            .find(Attr(&quot;class&quot;, &quot;price_color&quot;))
            .next()
            .unwrap()
            .text();

        // println!(&quot;{:#?} &quot;, url);
        wtr.write_record(&amp;[&amp;url, &amp;price, &amp;name]).unwrap();
    }

    Ok(())
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    for i in 1..50 {
        test(&amp;i).await.unwrap();
    }
    Ok(())
}
</code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="asynchronous"><a class="header" href="#asynchronous">Asynchronous</a></h1>
<p>During scraping, most of the time is lost downloading file rather than computing.</p>
<p>However, with synchronous runtimes, pages are scraped one by one and so downloaded one by one. Each download can take time and idle the whole process. Therefore, if we can manage to not wait for the completion of each download, we will gain efficiency.</p>
<h3 id="python-1"><a class="header" href="#python-1">Python</a></h3>
<p>It is possible using the ‚Äúasyncio‚Äù library, and it might look like that:</p>
<pre><code class="language-python">import asyncio
import requests
import bs4 as bs
import csv

URL = &quot;http://books.toscrape.com/catalogue/page-%d.html&quot;


async def get_book(url, spamwriter):
    response = requests.get(url)
    if response.status_code == 200:
        content = response.content
        soup = bs.BeautifulSoup(content, 'lxml')
        articles = soup.find_all('article')

        for article in articles:
            information = [url]
            information.append(article.find(
                'p', class_='price_color').text)
            information.append(article.find('h3').find('a').get('title'))
            spamwriter.writerow(information)


async def main():
    with open('./test_async_python.csv', 'w') as csvfile:
        spamwriter = csv.writer(csvfile, delimiter=',')
        tasks = []
        for i in range(1, 50):
            tasks.append(asyncio.create_task(
                get_book(URL % i, spamwriter)))

        for task in tasks:
            await task

asyncio.run(main())
</code></pre>
<p>Python does provide the <code>async/await</code> terminology which makes it easier to read and write.</p>
<h3 id="rust-4"><a class="header" href="#rust-4">Rust</a></h3>
<p>Rust, on the contrary to Python, has been built with asynchronous computation in mind. It is thread-safe and extremely efficient. The fact that the language, in its nature. is super fast makes it great for coroutines. The code might look like that:</p>
<pre><code class="language-rust noplaypen editable">use csv::Writer;
use select::document::Document;
use select::predicate::{Attr, Name};
use std::fs::OpenOptions;

async fn test(i: &amp;i32) -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    let url = format!(&quot;http://books.toscrape.com/catalogue/page-{}.html&quot;, i);
    let response = reqwest::get(&amp;url).await?.text().await?;
    let file = OpenOptions::new()
        .write(true)
        .create(true)
        .append(true)
        .open(&quot;test2.csv&quot;)
        .unwrap();
    let mut wtr = Writer::from_writer(file);

    let document = Document::from(response.as_str());

    for node in document.find(Name(&quot;article&quot;)) {
        let name = match node.find(Name(&quot;h3&quot;)).next() {
            Some(h3) =&gt; h3.find(Name(&quot;a&quot;)).next().unwrap().text(),
            None =&gt; &quot;&quot;.to_string(),
        };
        let price = node
            .find(Attr(&quot;class&quot;, &quot;price_color&quot;))
            .next()
            .unwrap()
            .text();

        println!(&quot;{:#?} &quot;, url);
        wtr.write_record(&amp;[&amp;url, &amp;price, &amp;name]).unwrap();
    }

    Ok(())
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {

    let mut handles: std::vec::Vec&lt;_&gt; = Vec::new();
    for i in 1..50 {
        let job = tokio::spawn(async move { test(&amp;i).await });
        handles.push(job);
    }

    let mut results = Vec::new();
    for job in handles {
        results.push(job.await);
    }

    Ok(())
}
</code></pre>
<p>‚Äå</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
                <script src="ace.js" type="text/javascript" charset="utf-8"></script>
        <script src="editor.js" type="text/javascript" charset="utf-8"></script>
        <script src="mode-rust.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-dawn.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-tomorrow_night.js" type="text/javascript" charset="utf-8"></script>
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
                        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
                
    </body>
</html>
