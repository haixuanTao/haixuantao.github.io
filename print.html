<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Haixuan Xavier Tao</title>
                <meta name="robots" content="noindex" />
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
                <link rel="stylesheet" href="custom.css">
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="about-me.html">About Me</a></li><li class="chapter-item expanded "><a href="about-me/work.html"><strong aria-hidden="true">1.</strong> Work Experience</a></li><li class="chapter-item expanded "><a href="about-me/education.html"><strong aria-hidden="true">2.</strong> Education</a></li><li class="chapter-item expanded "><a href="about-me/skills.html"><strong aria-hidden="true">3.</strong> Skills</a></li><li class="chapter-item expanded affix "><li class="part-title">Latest Posts</li><li class="chapter-item expanded "><a href="03-deep_learning_in_rust.html"><strong aria-hidden="true">4.</strong> 07.2020 - Deep Learning in Rust</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="deep-learning/batch_inference.html"><strong aria-hidden="true">4.1.</strong> Batch Inference</a></li><li class="chapter-item expanded "><a href="deep-learning/bert-server.html"><strong aria-hidden="true">4.2.</strong> Bert Server</a></li><li class="chapter-item expanded "><a href="deep-learning/conclusion.html"><strong aria-hidden="true">4.3.</strong> Conclusion</a></li></ol></li><li class="chapter-item expanded "><a href="02-polars-vs-rust.html"><strong aria-hidden="true">5.</strong> 04.2020 - Pandas vs Polars</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="pandas-polars/020-reading.html"><strong aria-hidden="true">5.1.</strong> Reading</a></li><li class="chapter-item expanded "><a href="pandas-polars/021-apply.html"><strong aria-hidden="true">5.2.</strong> Apply</a></li><li class="chapter-item expanded "><a href="pandas-polars/22-merging.html"><strong aria-hidden="true">5.3.</strong> Merging</a></li><li class="chapter-item expanded "><a href="pandas-polars/23-groupby.html"><strong aria-hidden="true">5.4.</strong> Groupby</a></li><li class="chapter-item expanded "><a href="pandas-polars/24-conculsion.html"><strong aria-hidden="true">5.5.</strong> Conclusion</a></li></ol></li><li class="chapter-item expanded "><a href="01-pandas-vs-rust.html"><strong aria-hidden="true">6.</strong> 03.2020 - Pandas vs Rust</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="pandas-rust/010-reading.html"><strong aria-hidden="true">6.1.</strong> Reading</a></li><li class="chapter-item expanded "><a href="pandas-rust/011-filtering.html"><strong aria-hidden="true">6.2.</strong> Filtering</a></li><li class="chapter-item expanded "><a href="pandas-rust/012-groupby.html"><strong aria-hidden="true">6.3.</strong> Groupby</a></li><li class="chapter-item expanded "><a href="pandas-rust/013-mutation.html"><strong aria-hidden="true">6.4.</strong> Mutation</a></li><li class="chapter-item expanded "><a href="pandas-rust/014-merging.html"><strong aria-hidden="true">6.5.</strong> Merging</a></li><li class="chapter-item expanded "><a href="pandas-rust/15-conclusion.html"><strong aria-hidden="true">6.6.</strong> Conclusion</a></li></ol></li><li class="chapter-item expanded "><a href="00-scraping.html"><strong aria-hidden="true">7.</strong> 02.2020 - Scraping Rust vs Python</a></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">Haixuan Xavier Tao</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="hey--welcome-to-my-portfolio-"><a class="header" href="#hey--welcome-to-my-portfolio-">Hey 🤗 Welcome to my Portfolio 🍾</a></h1>
<img alt="me" src="me.jpeg" style="border-radius:10%; margin-left: auto; margin-top: 1em; margin-right: auto; display: block" width="400" />
<p><a href="https://www.linkedin.com/in/haixuan-xavier-tao-7460b1102/"><img src="https://img.shields.io/badge/LinkedIn-0077B5?logo=linkedin&amp;logoColor=white&amp;label=Haixuan%20Xavier%20Tao" alt="Linkedin" /></a>
<a href="https://github.com/haixuanTao/"><img src="https://img.shields.io/github/followers/haixuantao?style=social" alt="GitHub followers" /></a>
<a href="https://www.reddit.com/user/peterparkrust"><img src="https://img.shields.io/reddit/user-karma/combined/peterparkrust?style=social" alt="Reddit User Karma" /></a></p>
<p>As a Data engineer, I'm very passionate about creating innovative solution to important problem.</p>
<p>I&quot;m working extensively with Rust, trying to figure out whether it can be a replacement for Python Data Science work.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="work-experience"><a class="header" href="#work-experience">Work Experience</a></h1>
<h3 id="dec-2020---now-central-bank-of-france-data-engineer"><a class="header" href="#dec-2020---now-central-bank-of-france-data-engineer">Dec 2020 - Now, Central Bank of France, Data Engineer</a></h3>
<p>Worked on a automated checks of Bank loan using NER, NLP, and CV.</p>
<blockquote>
<p><a href="https://events.linuxfoundation.org/lf-ai-data-day-eu-virtual/program/schedule/">🎤 Speaker at the Linux Foundation AI &amp; Data Days Europe on: Why ONNX Runtime Matters for Deploying AI in Institution.</a></p>
</blockquote>
<h3 id="sep-2020---dec-2020-insee-researcher"><a class="header" href="#sep-2020---dec-2020-insee-researcher">Sep 2020 - Dec 2020, INSEE*, Researcher</a></h3>
<p>Built an experimental statistics of the present population in France at every hour for 3 months on a 100 meter grid based on mobile phone traffic data.</p>
<blockquote>
<p><a href="https://coms.events/NTTS2021/data/abstracts/en/abstract_0108.html">📃 Published a paper at NTTS 2021 on a novel approach for estimating population using Mobile Phone Data.</a></p>
</blockquote>
<h3 id="jan-2020---sep-2020-independant-consultant-full-stack-engineer"><a class="header" href="#jan-2020---sep-2020-independant-consultant-full-stack-engineer">Jan 2020 - Sep 2020, Independant Consultant, Full Stack Engineer</a></h3>
<p>Empowered SMEs with Web Technologies.</p>
<h3 id="jul-2019---dec-2019-boston-consulting-group-data-scientist-intern"><a class="header" href="#jul-2019---dec-2019-boston-consulting-group-data-scientist-intern">Jul 2019 - Dec 2019, Boston Consulting Group, Data Scientist Intern</a></h3>
<p>Helped a large fashion retailer build a stocks optimizer for more than 100+ different markets.</p>
<h3 id="jul-2017---jul-2018-bnp-paribas-data-scientist-intern"><a class="header" href="#jul-2017---jul-2018-bnp-paribas-data-scientist-intern">Jul 2017 - Jul 2018, BNP Paribas, Data Scientist Intern</a></h3>
<p>Developed a corporate credit scoring and pricing algorithm leading to the lending of 100 millions € of unsecured loan for SME in the UK. </p>
<p>*<em>INSEE: French national institute for statistical and economic studies</em></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="education"><a class="header" href="#education">Education</a></h1>
<h3 id="2015-2019-ecole-centrale-paris-diplome-ingénieur-grande-ecole"><a class="header" href="#2015-2019-ecole-centrale-paris-diplome-ingénieur-grande-ecole">2015-2019, Ecole Centrale Paris, Diplome Ingénieur Grande Ecole</a></h3>
<p>Majored in Applied Mathematics</p>
<p>Awards:</p>
<ul>
<li>2500 euros Innovation award for building an European Statistics search engine</li>
<li>2nd Place at BCG Gamma Data Challenge on Preventive Health Care Measure Optimization</li>
<li>1st Place with a 1500€ award at Schlumberger Hackathon on deep learning applied to Lithology</li>
</ul>
<h3 id="2018-2019-essec-business-school-msc-data-science--business-analytics"><a class="header" href="#2018-2019-essec-business-school-msc-data-science--business-analytics">2018-2019, ESSEC Business School, Msc Data Science &amp; Business Analytics</a></h3>
<p>Double Major in Data Science and Business Strategy</p>
<p>Awards:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=M7GXZ3cjviM">1st Place at I-COM Data Science Hackathon - Warner Bros. Challenge</a> </li>
<li>2nd Place at Oliver Wyman Data Challenge on Paris Public Parking Pricing </li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="skills"><a class="header" href="#skills">Skills</a></h1>
<h3 id="languages"><a class="header" href="#languages">Languages</a></h3>
<p>French, English, Mandarin (Basic reading and writing)</p>
<h3 id="coding-languages"><a class="header" href="#coding-languages">Coding Languages</a></h3>
<p>Rust, Python, C/C++, Javascript, Typescript, Git, Docker, Kubernetes</p>
<h3 id="sports"><a class="header" href="#sports">Sports</a></h3>
<p>Sailing ⛵ and Kitesurfing 🏄</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="deep-learning-in-rust"><a class="header" href="#deep-learning-in-rust">Deep Learning in Rust</a></h1>
<p><a href="https://github.com/haixuanTao/onnxruntime-rs/"><img src="https://img.shields.io/github/stars/haixuanTao/onnxruntime-rs?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a>
<a href="https://github.com/haixuanTao/onnxruntime-rs/"><img src="https://img.shields.io/github/forks/haixuanTao/onnxruntime-rs?style=social&amp;label=Fork&amp;maxAge=2592000" alt="GitHub forks" /></a>
<a href="https://github.com/haixuanTao/onnxruntime-rs/"><img src="https://img.shields.io/github/last-commit/haixuantao/onnxruntime-rs" alt="GitHub stars" /></a></p>
<p>I have searched for months for a way to do Deep Learning(DL) Inference with Rust on GPU and I finally did it!!✨👏✨ This blog post will try to answer if Rust is a good fit for the job!</p>
<p><em>I have put an annexe at the end with the definition of Deep Learning words.</em></p>
<h2 id="my-setup"><a class="header" href="#my-setup">My setup</a></h2>
<p>I am using a Hugging Face <strong>tokenizer</strong> and a custom <strong>BERT</strong> Model from Pytorch that I have converted to <strong>ONNX</strong> to be run with <a href="https://github.com/nbigaouette/onnxruntime-rs"><strong>onnxruntime-rs</strong></a><strong>.</strong></p>
<p>I have tweaked <a href="https://github.com/nbigaouette/onnxruntime-rs">onnxruntime-rs</a> to do Deep Learning on GPU with CUDA 11 and onnxruntime 1.8 You can check it out on my git: <a href="https://github.com/haixuanTao/onnxruntime-rs">https://github.com/haixuanTao/onnxruntime-rs</a></p>
<p>Hardware-side, I have a 6 cores/12 threads CPU and a GTX 1050 GPU.</p>
<h2 id="unit-results"><a class="header" href="#unit-results">Unit Results</a></h2>
<h3 id="1-inference-time"><a class="header" href="#1-inference-time">1. Inference time</a></h3>
<table><thead><tr><th></th><th>Inferencing time per phrase</th><th>Speedup</th></tr></thead><tbody>
<tr><td>(Rust or Python) ONNX CPU</td><td>~125ms</td><td></td></tr>
<tr><td>(Rust or Python) ONNX GPU</td><td>~10ms</td><td><strong>x12</strong>🔥</td></tr>
</tbody></table>
<p><strong>DL inference using Onnxruntime will not be faster in Rust because both are wrapping the same C++ underlying engine. What is going to make a difference is the GPU.</strong></p>
<h3 id="2-preprocessing-time"><a class="header" href="#2-preprocessing-time">2. Preprocessing time</a></h3>
<table><thead><tr><th></th><th>Tokenizing time per phrase</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Python BertTokenizer</td><td>1000μs</td><td></td></tr>
<tr><td>Python BertTokenizerFast</td><td>200-600μs</td><td><strong>x2.5</strong>🔥</td></tr>
<tr><td>Rust <a href="https://docs.rs/tokenizers/0.10.1/tokenizers/">Tokenizer</a></td><td>50-150μs</td><td><strong>x4</strong>🔥</td></tr>
</tbody></table>
<p><strong>Gains can be made on DL Preprocessing! You can tokenize 4 times faster in Rust compared to Python, with the same Hugging Face Tokenizer library.</strong></p>
<h2 id="case-studies-results"><a class="header" href="#case-studies-results">Case studies Results</a></h2>
<p>Looking at those results alone is not enough. To dig a little further, I have built a DL data pipeline for batch inference and a DL server, to see what Rust for DL could be like on a daily basis.</p>
<h3 id="git-reference"><a class="header" href="#git-reference">Git reference</a></h3>
<p><em>Git of my tweaked onnxruntime-rs library with ONNX 1.8 and GPU features with CUDA 11:</em> <a href="https://github.com/haixuanTao/onnxruntime-rs">https://github.com/haixuanTao/onnxruntime-rs</a></p>
<p><em>Git of bert - onnxruntime-rs - Pipeline:</em>  <a href="https://github.com/haixuanTao/bert-onnx-rs-pipeline"><em>https://github.com/haixuanTao/bert-onnx-rs-pipeline</em></a></p>
<p><em>Git of bert - onnxruntime-rs - actix - server:</em> <a href="https://github.com/haixuanTao/bert-onnx-rs-server"><em>https://github.com/haixuanTao/bert-onnx-rs-server</em></a></p>
<p>‌</p>
<h3 id="annexe"><a class="header" href="#annexe">Annexe</a></h3>
<p><a href="https://onnx.ai/">ONNX</a> is an open format built to represent machine learning models. You can convert Pytorch, Tensorflow and Sklearn models into an ONNX format and then run them with <a href="https://github.com/nbigaouette/onnxruntime-rs">onnxruntime</a>.</p>
<p><a href="https://www.onnxruntime.ai/">ONNXRuntime</a> is the inference and optimized training engine that can read and run ONNX model. It is written in C++. There are official wrappers for Python, JS, JAVA, C and C++.</p>
<p><a href="https://github.com/nbigaouette/onnxruntime-rs">Onnxruntime-rs</a> is the Onnxruntime wrapper for Rust, it is a community-developed solution and does not wrap all the features of the C++ engine. I have tweaked the initial repo in order to have version 1.8 of Onnxruntime with the possibility of running it in GPU. My version is here: <a href="https://github.com/haixuanTao/onnxruntime-rs">https://github.com/haixuanTao/onnxruntime-rs</a> with branch onnx1.8.</p>
<p><a href="https://huggingface.co/transformers/main_classes/tokenizer.html">Tokenizer</a> enables you to transform words into index given a list of word.</p>
<p><a href="https://huggingface.co/transformers/model_doc/bert.html">BERT</a> is a Deep Learning model used for natural language processing.</p>
<p><a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPU</a> is a graphical processing unit for parallel computing. You will need CUDA and therefore an NVIDIA GPU to run Onnxruntime-rs.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="deep-learning-batch-inference-running-bert-on-a-csv"><a class="header" href="#deep-learning-batch-inference-running-bert-on-a-csv">Deep Learning batch inference: Running BERT on a CSV</a></h2>
<p><a href="https://github.com/haixuanTao/bert-onnx-rs-pipeline/"><img src="https://img.shields.io/github/stars/haixuanTao/bert-onnx-rs-pipeline?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a>
<a href="https://github.com/haixuanTao/bert-onnx-rs-pipeline/"><img src="https://img.shields.io/github/forks/haixuanTao/bert-onnx-rs-pipeline?style=social&amp;label=Fork&amp;maxAge=2592000" alt="GitHub forks" /></a>
<a href="https://github.com/haixuanTao/bert-onnx-rs-pipeline/"><img src="https://img.shields.io/github/last-commit/haixuantao/bert-onnx-rs-pipeline" alt="GitHub stars" /></a></p>
<p>Let say you want the inference of a BERT model on one column of a 10 thousand lines CSV.</p>
<p>On my setup, I got those timings:</p>
<table><thead><tr><th>10k phrases</th><th>Python</th><th>Rust</th></tr></thead><tbody>
<tr><td>Booting time</td><td>4s</td><td>1s</td></tr>
<tr><td>Encoding time</td><td>0.7s</td><td>0.3s</td></tr>
<tr><td>DL Inference time</td><td>75s</td><td>75s</td></tr>
<tr><td>Total time</td><td>80s</td><td>76s</td></tr>
<tr><td>Memory usage</td><td>1 GiB</td><td>0.7 GiB</td></tr>
</tbody></table>
<p><strong>As DL inference is taking the majority of the time, Rust will not increase performance and I would not bother with Rust and stay with Python for large batches of inference.</strong>   👍🐍</p>
<p><em>Git:</em>  <a href="https://github.com/haixuanTao/bert-onnx-rs-pipeline"><em>https://github.com/haixuanTao/bert-onnx-rs-pipeline</em></a></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="onnx-server-serving-bert-as-an-api"><a class="header" href="#onnx-server-serving-bert-as-an-api">ONNX Server: Serving BERT as an API</a></h2>
<p><a href="https://github.com/haixuanTao/bert-onnx-rs-server/"><img src="https://img.shields.io/github/stars/haixuanTao/bert-onnx-rs-server?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a>
<a href="https://github.com/haixuanTao/bert-onnx-rs-server/"><img src="https://img.shields.io/github/forks/haixuanTao/bert-onnx-rs-server?style=social&amp;label=Fork&amp;maxAge=2592000" alt="GitHub forks" /></a>
<a href="https://github.com/haixuanTao/bert-onnx-rs-server/"><img src="https://img.shields.io/github/last-commit/haixuantao/bert-onnx-rs-server" alt="GitHub stars" /></a></p>
<p>Let say you want to serve a BERT-like model through a server API endpoint.</p>
<p>On my setup, I got those metrics:</p>
<table><thead><tr><th></th><th>Python FastAPI</th><th>Rust Actix Web</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Encoding time</td><td>400μs</td><td>100μs</td><td></td></tr>
<tr><td>ONNX Inference time</td><td>~10ms</td><td>~10ms</td><td></td></tr>
<tr><td>API overhead time</td><td>~2ms</td><td>~1ms</td><td></td></tr>
<tr><td>Mean Latency</td><td>12.8ms</td><td>10.4ms</td><td>-20%⏰</td></tr>
<tr><td>Requests/secs</td><td>77.5 #/s</td><td>95 #/s</td><td>+22%🍾</td></tr>
</tbody></table>
<p><strong>The gain in performance comes from moving from considered “Fast” Python library to Rust: FastAPI -&gt; Actix Web, BertokenizerFast -&gt; Rust Tokenizer.</strong></p>
<p><strong>Thus, as Rust libraries tend to be faster than Python ones, the more functionalities you will have, the more speedup you’re going to see with Rust when serving Deep Learning.</strong></p>
<p><strong>That’s why, for performance-centric Deep Learning applications such as Real-Time Deep Learning, Embedded Deep Learning, Large-Scale AI servers …. I can definitely see Rust be a good fit!</strong> ❤️‍🦀</p>
<p><em>Git:</em> <a href="https://github.com/haixuanTao/bert-onnx-rs-server"><em>https://github.com/haixuanTao/bert-onnx-rs-server</em></a></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="in-conclusion-should-you-use-rust-for-deep-learning"><a class="header" href="#in-conclusion-should-you-use-rust-for-deep-learning">In conclusion, should you use Rust for Deep Learning?</a></h2>
<ul>
<li>Like the whole Rust ecosystem, you should use it if it’s the best tool for the job. If you really need performance 🏎️ and resilience🛡️, and you are ok to have a stack in Rust, go ahead🚀! But be aware that making Rust fast is not easy!</li>
<li>If you need quick prototyping with a data scientist friendly language, you should better use Python!</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pandas-vs-polars"><a class="header" href="#pandas-vs-polars">Pandas vs Polars</a></h1>
<p><a href="https://github.com/haixuanTao/dataframe-python-rust/"><img src="https://img.shields.io/github/stars/haixuanTao/dataframe-python-rust?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a>
<a href="https://github.com/haixuanTao/dataframe-python-rust/"><img src="https://img.shields.io/github/forks/haixuanTao/dataframe-python-rust?style=social&amp;label=Fork&amp;maxAge=2592000" alt="GitHub forks" /></a>
<a href="https://github.com/haixuanTao/dataframe-python-rust/"><img src="https://img.shields.io/github/last-commit/haixuantao/dataframe-python-rust" alt="GitHub stars" /></a></p>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>Everyone loves the API of Pandas. It’s fast, easy, and well documented. There are some rough edges, but most times, it’s just a blast.</p>
<p>Now, when it comes to production, Pandas is slightly trickier. Pandas does not scale very well… there is no multithreading… It’s not thread-safe… It’s not memory efficient.</p>
<p>But all those problems are the raison d’être of Rust.</p>
<p><strong>But what if, there was a DataFrame API written in Rust that solves all those issues and at the same time keeps a nice API?</strong></p>
<hr />
<h2 id="polars"><a class="header" href="#polars">Polars</a></h2>
<p>Well, <a href="https://github.com/ritchie46/polars"><strong>Polars</strong></a> tries to do just that. It allows you to do read, write, filter, apply functions, group by and merge, all in a <strong>thread-safe fashion</strong>.</p>
<p>It uses <a href="https://github.com/apache/arrow"><strong>Apache Arrow</strong></a>, a data framework purposely built for doing efficient data processing and data sharing across language.</p>
<h2 id="3-reasons-for-choosing-polars"><a class="header" href="#3-reasons-for-choosing-polars">3 reasons for choosing <strong>Polars</strong></a></h2>
<h3 id="reason-1-performance"><a class="header" href="#reason-1-performance">Reason #1. Performance.</a></h3>
<p>it’s killing it <a href="https://h2oai.github.io/db-benchmark/">performance-wise</a>.</p>
<h3 id="reason-2-the-api-is-straightforward"><a class="header" href="#reason-2-the-api-is-straightforward">Reason #2. The API is straightforward.</a></h3>
<p>Do you want to mutate the data? Use <code>apply</code>. Do you want to filter the data? use <code>filter</code>. Do you want to merge? Use <code>join</code> . There is not going to be rust syntax like <code>struct</code>, <code>derive</code>, <code>impl</code> …</p>
<h3 id="reason-3-no-troubles-with-the-borrow-checker"><a class="header" href="#reason-3-no-troubles-with-the-borrow-checker">Reason #3. No troubles with the borrow checker.</a></h3>
<p>It uses Arc, Mutex like referencing, which means that you can clone variables as much as you like. Variables are only references to in-memory data. No more fighting with the borrow checker. Mutability is limited to the API calls, which preserve the consistency/thread-safety of the data.</p>
<h2 id="3-caveats-of-polars"><a class="header" href="#3-caveats-of-polars">3 caveats of <strong>Polars</strong></a></h2>
<h3 id="caveat-1-issues"><a class="header" href="#caveat-1-issues">‌‌Caveat #1. Issues…</a></h3>
<p>Building a DataFrame API is hard. It’s so hard, Pandas took 12 years to reach 1.0.0. And,  as Polars is rather young, you may face unexpected issues. In my cases, there were issues with <a href="https://github.com/ritchie46/polars/issues/387">\n characters</a>,<a href="https://github.com/ritchie46/polars/pull/399"> double quotes characters</a>, and <a href="https://github.com/ritchie46/polars/pull/400">long utf8</a>.</p>
<p>On the other hand, those are great first issues to get started with contribution and getting better at Rust 🔨</p>
<h3 id="caveat-2-getting-comfortable-with-two-apis-polars-and-arrow"><a class="header" href="#caveat-2-getting-comfortable-with-two-apis-polars-and-arrow">Caveat #2. Getting comfortable with two APIs: Polars and Arrow.</a></h3>
<p>As many of the heavy liftings are done using the Apache Arrow backend, you’ll have to get used to reading both documentation. Both documentations are pretty straightforward, but it might feel tiring for someone who was looking for a drop-in replacement of Pandas.</p>
<h3 id="caveat-3-compiling-time"><a class="header" href="#caveat-3-compiling-time">Caveat #3. Compiling time…</a></h3>
<p>Sadly, compiling time takes around <a href="https://github.com/ritchie46/polars/issues/402">6min</a> uncached. And, it uses a lot of resources.</p>
<hr />
<h2 id="case-study"><a class="header" href="#case-study">Case Study</a></h2>
<p><strong>Now the question is, is it better than native Rust as I’ve explained</strong> <a href="https://able.bio/haixuanTao/data-manipulation-pandas-vs-rust--1d70e7fc"><strong>in my previous blog post</strong></a><strong>?</strong></p>
<p>Let’s take a hands-on comparison for a Data Pipeline and get a feel for it.</p>
<p>In this case study, I’m going to use the <a href="https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/data?select=2012-07+Stack+Overflow.7z">stack overflow kaggle dataset</a>. I’m going to read the database, parse the dates, make a merge between the first tag and the<a href="https://en.wikipedia.org/wiki/Comparison_of_programming_languages#Failsafe_I/O_and_system_calls"> Wikipedia comparison of programming language</a>. Group by the status of the question asked. And retrieve the distribution of language’s features within each ‘status’ of questions.</p>
<p>We’ll compare Polars API &amp; Native Rust generic heap structure to do this task.</p>
<ul>
<li><em>I’ll go slightly quicker on the native Rust, as I already put more details</em> <a href="https://able.bio/haixuanTao/data-manipulation-pandas-vs-rust--1d70e7fc"><em>here</em></a><em>.</em></li>
<li><em>Multithreading is done on 12 threads Intel(R) Core(TM) i7-8750H / 20G RAM.</em></li>
<li><em>The database is 4.2G big for around 3.6 Million rows.</em></li>
</ul>
<h3 id="polars-lazy"><a class="header" href="#polars-lazy">Polars Lazy</a></h3>
<p>Polars also offers a query optimized version called Lazy with a slightly different API. In my use case, I did not find it hard to go from one to the other, but I did not find any significant increase in performance either. The result is in the overall performance.</p>
<hr />
<h2 id="annexe-1"><a class="header" href="#annexe-1">‌Annexe</a></h2>
<h3 id="dask"><a class="header" href="#dask">Dask</a></h3>
<p>For the life of me, I tried to run <strong>dask</strong> for benchmarking but did not succeed in making it faster than native pandas. On the <strong>dask</strong> website, they say:</p>
<p><em>If your dataset fits comfortably into RAM on your laptop, then you may be better off just using Pandas. There may be simpler ways to improve performance than through parallelism</em></p>
<p>This means, there is this void in pandas optimization for data sized between 1Go to 1To. Dask seems to be a replacement of Spark but not pandas itself.</p>
<p>And even if it worked, performance increase would only be around 4-5x, from past experience</p>
<h3 id="cudf"><a class="header" href="#cudf">Cudf</a></h3>
<p>I tried to run <strong>Cudf</strong> on my 4G RAM GPU but run out of memory. I did not investigate further.</p>
<h3 id="vagrind"><a class="header" href="#vagrind">Vagrind</a></h3>
<p>I tried to run <strong>valgrind</strong> to do a profiling of the memory usage but it seems not to work with polars and native rust at this size.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="reading"><a class="header" href="#reading">Reading</a></h2>
<h3 id="reading-in-polars"><a class="header" href="#reading-in-polars">Reading in Polars</a></h3>
<p>Reading is pretty straightforward with many configurations possible.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use polars::prelude::*;

//...

    let mut df = CsvReader::from_path(path)?
        .with_n_threads(Some(1)) // comment for multithreading
        .with_encoding(CsvEncoding::LossyUtf8)
        .has_header(true)
        .finish()?;
<span class="boring">}
</span></code></pre></pre>
<h3 id="reading-in-native-rust"><a class="header" href="#reading-in-native-rust">Reading in Native Rust</a></h3>
<p>Reading in Rust using csv and serde requires that you already have a <code>struct</code> , in my case my struct is <code>utils::NativeDataFrame</code></p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    let file = File::open(path)?;

    let mut rdr = csv::ReaderBuilder::new().delimiter(b',').from_reader(file);
    let mut records: Vec&lt;utils::NativeDataFrame&gt; = rdr
        .deserialize()
        .into_iter()
        .filter_map(|result| match result {
            Ok(rec) =&gt; rec,
            Err(e) =&gt; None,
        })
        .collect();
<span class="boring">}
</span></code></pre></pre>
<h3 id="performance"><a class="header" href="#performance">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td><strong>Native Rust (Single thread)</strong></td><td><strong>12 s</strong></td><td><strong>2.4x</strong></td></tr>
<tr><td>Polars(Single thread)</td><td>19 s</td><td>1.5x</td></tr>
<tr><td>Polars(Multithread)</td><td>22 s</td><td>1.3x</td></tr>
<tr><td>Pandas</td><td>29.6 s</td><td></td></tr>
</tbody></table>
<p>For reading, <strong>Polars</strong> has a nice happy and I bet it’s also doing some indexing which explains the difference in timing between the native implementation. There seems to be a bug for multithreaded Polars that makes it slower than single-threaded. <em>(Probably a good first issue…</em> 🤪 <em>)</em></p>
<p>Note that reading is bound by the reading speed of my SSD around ~300Mb/s.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="apply"><a class="header" href="#apply">Apply</a></h2>
<h3 id="applying-function-in-polars"><a class="header" href="#applying-function-in-polars">Applying Function in Polars</a></h3>
<p>To Apply a function in Polars, you can use the default <code>apply</code> or <code>may_apply</code>. I prefer the latter. This will mutate the original data.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn str_to_date(dates: &amp;Series) -&gt; std::result::Result&lt;Series, PolarsError&gt; {
    let fmt = Some(&quot;%m/%d/%Y %H:%M:%S&quot;);

    Ok(dates.utf8()?.as_date64(fmt)?.into_series())
}

fn count_words(dates: &amp;Series) -&gt; std::result::Result&lt;Series, PolarsError&gt; {
    Ok(dates
	.utf8()?
	.into_iter()
	.map(|opt_name: Option&lt;&amp;str&gt;| 
		 opt_name.map(|name: &amp;str| name.split(&quot; &quot;).count() as u64
	))
	.collect::&lt;UInt64Chunked&gt;()
	.into_series())
}

// ...

    // Apply Format Date
    df.may_apply(&quot;PostCreationDate&quot;, str_to_date)?;

    let t_formatting = Instant::now();

    // Apply Custom counting words in string
    df.may_apply(&quot;BodyMarkdown&quot;, count_words)?;
<span class="boring">}
</span></code></pre></pre>
<h3 id="applying-function-in-native-rust"><a class="header" href="#applying-function-in-native-rust">Applying Function in Native Rust</a></h3>
<p>Now, what I like about native rust mutation, is that the syntax is standard among iterator, and so once you get comfortable with the syntax, you can apply it everywhere 😀</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use chrono::{DateTime, NaiveDate, NaiveDateTime, NaiveTime};
// use rayon::prelude::*;  for multithreads

    // Apply Format Date
    let fmt = &quot;%m/%d/%Y %H:%M:%S&quot;;

    records
	.iter_mut()  // .par_iter_mut() for multithreads
	.for_each(|record: &amp;mut utils::NativeDataFrame| {
	    record.PostCreationDatetime =
		match DateTime::parse_from_str(
		  record.PostCreationDate.as_ref().unwrap(), fmt) {
		    Ok(dates) =&gt; Some(dates),
		    Err(_) =&gt; None,
		}
	});

    // Apply Custom Formatting counting words in string
    records
	.iter_mut() // .par_iter_mut() for multithreads
	.for_each(|record: &amp;mut utils::NativeDataFrame| {
	    record.CountWords =
		Some(
	  record.BodyMarkdown.as_ref().unwrap().split(' ').count() as f64
		)
	});
<span class="boring">}
</span></code></pre></pre>
<h3 id="performance-for-formatting-dates"><a class="header" href="#performance-for-formatting-dates">Performance for formatting dates</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>.98 s</td><td>8x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>.148 s</strong></td><td><strong>52x</strong></td></tr>
<tr><td>Polars(Single thread)</td><td>.88 s</td><td>8.8x</td></tr>
<tr><td>Pandas</td><td>7.8 s</td><td></td></tr>
</tbody></table>
<h3 id="performance-for-counting-words"><a class="header" href="#performance-for-counting-words">Performance for counting words</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>9 s</td><td>2.7x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>1.3 s</strong></td><td><strong>19x</strong></td></tr>
<tr><td>Polars(Single thread)</td><td>9 s</td><td>2.7x</td></tr>
<tr><td>Pandas</td><td>24.8 s</td><td></td></tr>
</tbody></table>
<p><strong>Polars</strong> does not seem to offer increased performance over the standard library on a single thread, and I couldn’t find a way to do multi-threaded apply… In this scenario, I’ll prefer native rust.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="merging"><a class="header" href="#merging">Merging</a></h2>
<h3 id="merging-in-polars"><a class="header" href="#merging-in-polars">Merging in Polars</a></h3>
<p>Merging in Polars is dead easy, although the number of strategy for filling <code>none</code> values are limited for now.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    df = df
        .join(&amp;df_wikipedia, &quot;Tag1&quot;, &quot;Language&quot;, JoinType::Left)?
        .fill_none(FillNoneStrategy::Min)?;
<span class="boring">}
</span></code></pre></pre>
<h3 id="merging-in-native-rust"><a class="header" href="#merging-in-native-rust">Merging in Native Rust</a></h3>
<p>Merging in native Rust can be done with nested structure and pairing with a Hashmap:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut hash_wikipedia: &amp;HashMap&lt;&amp;String, &amp;utils::WikiDataFrame&gt; = &amp;records_wikipedia
    .iter()
    .map(|record| (record.Language.as_ref().unwrap(), record))
    .collect();

records.iter_mut().for_each(|record| {
    record.Wikipedia = match hash_wikipedia.get(&amp;record.Tag1.as_ref().unwrap()) {
        Some(wikipedia) =&gt; Some(wikipedia.clone().clone()),
        None =&gt; None,
    }
});
<span class="boring">}
</span></code></pre></pre>
<h3 id="performance-1"><a class="header" href="#performance-1">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>.680 s</td><td>6.3x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>.215 s</strong></td><td><strong>20x</strong></td></tr>
<tr><td>Polars</td><td>.543 s</td><td>8x</td></tr>
<tr><td>Pandas</td><td>4.347 s</td><td></td></tr>
</tbody></table>
<p>For merging, having a nested structure with <code>None</code> values can be very verbose. Having a flat structure is a huge plus. So, I’ll recommend using <strong>Polars</strong> if merging is key.</p>
<p><em>I’m not sure If polars merging is done multi-threaded or not. It seems to be multithreaded by default.</em></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="groupby"><a class="header" href="#groupby">Groupby</a></h2>
<h3 id="group-by-in-polars"><a class="header" href="#group-by-in-polars">Group By in Polars</a></h3>
<p>Group by in polars are really easy</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    // Groupby series as a clone of reference
    let groupby_series = vec![
        df.column(&quot;OpenStatus&quot;)?.clone(),
    ];

    let target_column = vec![
        &quot;ReputationAtPostCreation&quot;,
        &quot;OwnerUndeletedAnswerCountAtPostTime&quot;,
        &quot;Imperative&quot;,
        &quot;Object-oriented&quot;,
        &quot;Functional&quot;,
        &quot;Procedural&quot;,
        &quot;Generic&quot;,
        &quot;Reflective&quot;,
        &quot;Event-driven&quot;,
    ];

    let groups = df
        .groupby_with_series(groupby_series, false)?
        .select(target_column)
        .mean()?;
<span class="boring">}
</span></code></pre></pre>
<h3 id="group-by-in-native-rust"><a class="header" href="#group-by-in-native-rust">Group By in Native Rust</a></h3>
<p>This part is quite tricky. To make a group by in a thread-safe manner, you’ll need to use a Hashmap with <code>fold</code>. Note that, <a href="https://docs.rs/rayon/0.7.1/rayon/iter/trait.ParallelIterator.html#method.fold">parallel fold</a>s are slightly more complicated as folding requires passing data around threads.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    let groups_hash: HashMap&lt;String, (utils::GroupBy, i16)&gt; = records
        .iter() // .par_iter()
        .fold(
            HashMap::new(), // || HashMap::new()
            |mut hash_group: HashMap&lt;String, (utils::GroupBy, i16)&gt;, record| {
                let group: utils::GroupBy = if let Some(wiki) = &amp;record.Wikipedia {
                    utils::GroupBy {
                        status: record.OpenStatus.as_ref().unwrap().to_string(),
                        ReputationAtPostCreation: record.ReputationAtPostCreation.unwrap(),
                        OwnerUndeletedAnswerCountAtPostTime: record
                            .OwnerUndeletedAnswerCountAtPostTime
                            .unwrap(),
                        Imperative: wiki.Imperative.unwrap(),
                        ObjectOriented: wiki.ObjectOriented.unwrap(),
                        Functional: wiki.Functional.unwrap(),
                        Procedural: wiki.Procedural.unwrap(),
                        Generic: wiki.Generic.unwrap(),
                        Reflective: wiki.Reflective.unwrap(),
                        EventDriven: wiki.EventDriven.unwrap(),
                    }
                } else {
                    utils::GroupBy {
                        status: record.OpenStatus.as_ref().unwrap().to_string(),
                        ReputationAtPostCreation: record.ReputationAtPostCreation.unwrap(),
                        OwnerUndeletedAnswerCountAtPostTime: record
                            .OwnerUndeletedAnswerCountAtPostTime
                            .unwrap(),
                        ..Default::default()
                    }
                };
                if let Some((previous, count)) = hash_group.get_mut(&amp;group.status.to_string()) {
                    *previous = previous.clone() + group;
                    *count += 1;
                } else {
                    hash_group.insert(group.status.to_string(), (group, 1));
                };
                hash_group
            },
        ); // }
           // .reduce(
           //     || HashMap::new(),
           //     |prev, other| {
           //         let set1: HashSet&lt;String&gt; = prev.keys().cloned().collect();
           //         let set2: HashSet&lt;String&gt; = other.keys().cloned().collect();
           //         let unions: HashSet&lt;String&gt; = set1.union(&amp;set2).cloned().collect();
           //         let mut map = HashMap::new();
           //         for key in unions.iter() {
           //             map.insert(
           //                 key.to_string(),
           //                 match (prev.get(key), other.get(key)) {
           //                     (Some((previous, count_prev)), Some((group, count_other))) =&gt; {
           //                         (previous.clone() + group.clone(), count_prev + count_other)
           //                     }
           //                     (Some(previous), None) =&gt; previous.clone(),
           //                     (None, Some(other)) =&gt; other.clone(),
           //                     (None, None) =&gt; (utils::GroupBy::new(), 0),
           //                 },
           //             );
           //         }
           //         map
           //     },
           // );

    let groups: Vec&lt;utils::GroupBy&gt; = groups_hash
        .iter()
        .map(|(_, (group, count))| utils::GroupBy {
            status: group.status.to_string(),
            ReputationAtPostCreation: group.ReputationAtPostCreation / count.clone() as f64,
            OwnerUndeletedAnswerCountAtPostTime: group.OwnerUndeletedAnswerCountAtPostTime
                / count.clone() as f64,
            Imperative: group.Imperative / count.clone() as f64,
            ObjectOriented: group.ObjectOriented / count.clone() as f64,
            Functional: group.Functional / count.clone() as f64,
            Procedural: group.Procedural / count.clone() as f64,
            Generic: group.Generic / count.clone() as f64,
            Reflective: group.Reflective / count.clone() as f64,
            EventDriven: group.EventDriven / count.clone() as f64,
        })
        .collect();
<span class="boring">}
</span></code></pre></pre>
<p><em>Uncomment for multithreading</em></p>
<h3 id="performance-2"><a class="header" href="#performance-2">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>.536 s</td><td>2x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>.115 s</strong></td><td><strong>9.5x</strong></td></tr>
<tr><td>Polars(Single thread)</td><td>.131 s</td><td>8.3x</td></tr>
<tr><td>Polars(Multithread)</td><td>.125 s</td><td>8.8x</td></tr>
<tr><td>Pandas</td><td>1.1 s</td><td></td></tr>
</tbody></table>
<p>Group By and Merging are the ideal case for <strong>Polars</strong>. You’ll get 8x more performance than Pandas on a single thread, and Polars handle multi-threading although, in my case, it didn’t matter much.</p>
<p>It can be done with native rust, but judging by the size of the code, it’s not an ideal use case.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<h3 id="performance-overall"><a class="header" href="#performance-overall">Performance overall</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>24 s</td><td>3.3x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>13.7 s</strong></td><td><strong>5.8x</strong></td></tr>
<tr><td>Polars (Single thread)</td><td>30 s</td><td>2.6x</td></tr>
<tr><td>Polars (Multithread)</td><td>33 s</td><td>2.4x</td></tr>
<tr><td>Polars (lazy, Multithreaded)</td><td>32s</td><td>2.5x</td></tr>
<tr><td>Pandas</td><td>80 s</td><td></td></tr>
</tbody></table>
<p>As reading is io bound, I wanted to make a benchmark of pure performance.</p>
<h3 id="performance-without-reading"><a class="header" href="#performance-without-reading">Performance without Reading</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Speedup Pandas</th></tr></thead><tbody>
<tr><td>Native Rust (Single thread)</td><td>12 s</td><td>3.3x</td></tr>
<tr><td><strong>Native Rust (Multithread)</strong></td><td><strong>1.7 s</strong></td><td><strong>23x</strong></td></tr>
<tr><td>Polars (Single thread)</td><td>10 s</td><td>4x</td></tr>
<tr><td>Polars (Multithread)</td><td>11 s</td><td>3.6x</td></tr>
<tr><td>Polars (Lazy, Multithread)</td><td>11 s</td><td>3.6x</td></tr>
<tr><td>Pandas</td><td>40 s</td><td></td></tr>
</tbody></table>
<p>‌</p>
<h3 id="overall-takeaway"><a class="header" href="#overall-takeaway">Overall takeaway</a></h3>
<ul>
<li>Use Polars if you want a great API.</li>
<li>Use Polars for merging and group by.</li>
<li>Use Polars for <a href="https://en.wikipedia.org/wiki/SIMD">single instruction multiple data(SIMD) </a>operation.</li>
<li>Use Native Rust if you’re already familiar with rust generic heap structure like vectors and hashmap.</li>
<li>Use Native Rust for linear mutation of the data with <code>map</code> and <code>fold</code>. You’ll get O(n) scalability that can be parallelized almost instantly with <code>rayon</code>.</li>
<li>Use pandas when performance, scalability, memory usage does not matter.</li>
</ul>
<p>For me, both Polars and native Rust makes a lot of sense for data between 1Go and 1To, single-threaded or not.</p>
<p>I’ll invite you to make your own opinion. The code is available here: <a href="https://github.com/haixuanTao/dataframe-python-rust">https://github.com/haixuanTao/dataframe-python-rust</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pandas-vs-rust"><a class="header" href="#pandas-vs-rust">Pandas vs Rust</a></h1>
<p><a href="https://github.com/haixuanTao/Data-Manipulation-Rust-Pandas/"><img src="https://img.shields.io/github/stars/haixuanTao/Data-Manipulation-Rust-Pandas?style=social&amp;label=Star&amp;maxAge=2592000" alt="GitHub stars" /></a>
<a href="https://github.com/haixuanTao/Data-Manipulation-Rust-Pandas/"><img src="https://img.shields.io/github/forks/haixuanTao/Data-Manipulation-Rust-Pandas?style=social&amp;label=Fork&amp;maxAge=2592000" alt="GitHub forks" /></a>
<a href="https://github.com/haixuanTao/Data-Manipulation-Rust-Pandas/"><img src="https://img.shields.io/github/last-commit/haixuantao/Data-Manipulation-Rust-Pandas" alt="GitHub stars" /></a></p>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>Pandas is the main Data analysis package of Python. For many reasons, Native Python has very poor performance on data analysis without vectorizing with NumPy and the likes. And historically, Pandas has been created by Wes McKinney to package those optimisations in a nice API to facilitate data analysis in Python.</p>
<p>This, however, is not necessary for Rust. Rust has great data performance natively. This is why Rust doesn’t really need a package like Pandas.</p>
<p>I believe the rustiest way to do Data Manipulation in Rust would be to build a <strong>heap of data struct</strong>.</p>
<p>This is my experience and reasoning comparing <strong>Pandas vs Rust</strong>.</p>
<h3 id="data"><a class="header" href="#data">Data</a></h3>
<p>Performance benchmarks are done on this very random dataset: <a href="https://www.kaggle.com/START-UMD/gtd">https://www.kaggle.com/START-UMD/gtd</a> that offers around 160,000 lines / 130 columns for a total size of 150Mb. The size of this dataset corresponds to the type of dataset I regularly encounter, that’s why I chose this one. It isn’t the biggest dataset in the world, and, more studies should probably be done on a larger dataset.</p>
<p>The merge will be done with another random dataset: <a href="https://datacatalog.worldbank.org/dataset/world-development-indicators">https://datacatalog.worldbank.org/dataset/world-development-indicators</a>, the <code>WDICountry.csv</code></p>
<h3 id="disclaimer"><a class="header" href="#disclaimer">Disclaimer</a></h3>
<p>In many ways, Pandas can be optimized, but optimisation comes at a cost, whether it is hardware (e.g. Cluster #Dask, GPU #Cudf) or dependency on the reliability and maintenance of those optimisation packages.</p>
<p>What I like about using Native Rust is that it doesn’t rely on additional hardware nor does it depends on additional packages. This solution doesn’t require an additional layer of abstraction, which makes it way more intuitive in many regards.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="reading-1"><a class="header" href="#reading-1">Reading</a></h2>
<h3 id="pandas"><a class="header" href="#pandas">[Pandas]</a></h3>
<p>Reading and instantiating Data in Pandas is pretty straightforward, and handles by default many data quality problems:</p>
<pre><code class="language-python">import pandas as pd

path = &quot;/home/peter/Documents/TEST/RUST/terrorism/src/globalterrorismdb_0718dist.csv&quot;
df = pd.read_csv(path)
</code></pre>
<h3 id="rust-reading-csv"><a class="header" href="#rust-reading-csv">[Rust] Reading CSV</a></h3>
<p>For Rust, Managing bad quality data is very very tedious. In this dataset, some fields are empty, some lines are badly formatted, and some are not UTF-8 encoded.</p>
<p>To open the CSV, I used the <code>csv</code> crate but it does not solve all the issues listed above. With well-formatted data, reading can be done like so:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let path = &quot;/home/peter/Documents/TEST/RUST/terrorism/src/foo.csv&quot;
let mut rdr = csv::Reader::from_path(path).unwrap();
<span class="boring">}
</span></code></pre></pre>
<p>But with bad quality formatting, mine looked like this:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::fs::File;    
use encoding_rs::WINDOWS_1252;
use encoding_rs_io::DecodeReaderBytesBuilder;

// ...

    let file = File::open(path)?;
    let transcoded = DecodeReaderBytesBuilder::new()
        .encoding(Some(WINDOWS_1252))
        .build(file);
    let mut rdr = csv::ReaderBuilder::new()
        .delimiter(b',')
        .from_reader(transcoded); 
<span class="boring">}
</span></code></pre></pre>
<p><em>ref:</em> <a href="https://stackoverflow.com/questions/53826986/how-to-read-a-non-utf8-encoded-csv-file"><em>https://stackoverflow.com/questions/53826986/how-to-read-a-non-utf8-encoded-csv-file</em></a></p>
<h3 id="rust-instantiating-the-data"><a class="header" href="#rust-instantiating-the-data">[Rust] Instantiating the data</a></h3>
<p>To instantiate the data, I used Serde <a href="https://serde.rs/">https://serde.rs/</a> for serializing and deserializing my data.</p>
<p>To use Serde, I needed to make a struct of my data. But, having a struct of my data is great has it makes my code follow a model-based coding paradigm with a well-defined type for each field. It also enables me to implement traits and methods on top of them.</p>
<p>However, the data I wanted to use has 130 columns… And, It seemed that there is no way to generate the definition of the struct automatically.</p>
<p>To avoid doing the definition manually, I had to build my own struct generator:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn inspect(path: &amp;str) {
    let mut record: Record = HashMap::new();

    let mut rdr = csv::Reader::from_path(path).unwrap();

    for result in rdr.deserialize() {
        match result {
            Ok(rec) =&gt; {
                record = rec;
                break;
            }
            Err(e) =&gt; (),
        };
    }
    // Print Struct
    println!(&quot;#[skip_serializing_none]&quot;);
    println!(&quot;#[derive(Debug, Deserialize, Serialize)]&quot;);
    println!(&quot;struct DataFrame {{&quot;);
    for (key, value) in &amp;record {
        println!(&quot;    #[serialize_always]&quot;);

        match value.parse::&lt;i64&gt;() {
            Ok(n) =&gt; {
                println!(&quot;    {}: Option&lt;i64&gt;,&quot;, key);
                continue;
            }
            Err(e) =&gt; (),
        }
        match value.parse::&lt;f64&gt;() {
            Ok(n) =&gt; {
                println!(&quot;    {}: Option&lt;f64&gt;,&quot;, key);
                continue;
            }
            Err(e) =&gt; (),
        }
        println!(&quot;    {}: Option&lt;String&gt;,&quot;, key);
    }
    println!(&quot;}}&quot;);
}
<span class="boring">}
</span></code></pre></pre>
<p>This generated the struct as follows:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use serde::{Deserialize, Serialize};
use serde_with::skip_serializing_none;

#[skip_serializing_none]
#[derive(Debug, Clone, Deserialize, Serialize)]
struct DataFrame {
    #[serialize_always]
    individual: Option&lt;f64&gt;,
    #[serialize_always]
    natlty3_txt: Option&lt;String&gt;,
    #[serialize_always]
    ransom: Option&lt;f64&gt;,
    #[serialize_always]
    related: Option&lt;String&gt;,
    #[serialize_always]
    gsubname: Option&lt;String&gt;,
    #[serialize_always]
    claim2: Option&lt;String&gt;,
    #[serialize_always]

    // ...
<span class="boring">}
</span></code></pre></pre>
<p><em>skip_serializing_none: Avoid having error on empty fields in the CSV.</em></p>
<p><em>serialize_always: Makes the number of field when writing csv fixed.</em></p>
<p>Now, that I had my struct, I used serde serialization to populate a vector of struct:</p>
<pre><code>    let mut records: Vec&lt;DataFrame&gt; = Vec::new();

    for result in rdr.deserialize() {
        match result {
            Ok(rec) =&gt; {
                records.push(rec);
            }
            Err(e) =&gt; println!(&quot;{}&quot;, e),
        };
    }
</code></pre>
<p>This generated my vector of struct, hooray 🎉</p>
<p>On a general note with Rust, you shouldn’t expect things to work as smoothly as it would with Python.</p>
<p>On reading / instantiating data, <strong>Pandas</strong> wins hands down for CSV.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="filtering"><a class="header" href="#filtering">Filtering</a></h2>
<h3 id="pandas-1"><a class="header" href="#pandas-1">[Pandas]</a></h3>
<p>There are many ways to do filtering in pandas, the most common way for me is as follows:</p>
<pre><code class="language-python">df = df[df.country_txt == &quot;United States&quot;]
df.to_csv(&quot;python_output.csv&quot;)
</code></pre>
<h3 id="rust"><a class="header" href="#rust">[Rust]</a></h3>
<p>To do filtering in Rust, we can refer to the docs for vector in Rust <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html">https://doc.rust-lang.org/std/vec/struct.Vec.html</a></p>
<p>There is a large umbrella of methods for Vector filtering, with many nightly features that are going to be great for data manipulation when they ship. For this use case, I used the <code>retain</code> method has it was fitted my need perfectly:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    records.retain(|x| &amp;x.country_txt.unwrap() == &quot;United States&quot;);
    let mut wtr =
        csv::Writer::from_path(&quot;output_rust_filter.csv&quot;)?;

    for record in &amp;records {
        wtr.serialize(record)?;
    }
<span class="boring">}
</span></code></pre></pre>
<p><strong>One big difference between Pandas and Rust is that Rust filtering uses Closures (<em>eq. lambda function in python</em>) whereas Pandas filtering uses Pandas API based on columns. This means Rust can make more complex filters compared to Pandas. It also adds in readability in my opinion.</strong></p>
<h3 id="performance-3"><a class="header" href="#performance-3">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Mem Usage(Gb)</th></tr></thead><tbody>
<tr><td>Pandas</td><td>3.0s</td><td>2.5Gb</td></tr>
<tr><td>Rust</td><td>1.6s 🔥 -50%</td><td>1.7Gb 🔥 -32%</td></tr>
</tbody></table>
<p>Even though we’re using Pandas API for filtering, we get significantly better performance using Rust.</p>
<p>On Filtering, <strong>Rust</strong> seems to be more capable and faster. 🚅</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="groupby-1"><a class="header" href="#groupby-1">Groupby</a></h2>
<h3 id="pandas-2"><a class="header" href="#pandas-2">[Pandas]</a></h3>
<p>Group by are a big part of the data reduction pipeline in python, it goes usually as follows:</p>
<pre><code class="language-python">df = df.groupby(by=&quot;country_txt&quot;, as_index=False).agg(
    {&quot;nkill&quot;: &quot;sum&quot;, &quot;individual&quot;: &quot;mean&quot;, &quot;eventid&quot;: &quot;count&quot;}
)
df.to_csv(&quot;python_output_groupby.csv&quot;)
</code></pre>
<h3 id="rust-1"><a class="header" href="#rust-1">[Rust]</a></h3>
<p>For group by and data reduction, thanks to <a href="https://able.bio/insideoutclub">David Sanders</a>, group by can be done as follows:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use itertools::Itertools;


// ...

#[derive(Debug, Deserialize, Serialize)]
struct GroupBy {
    country: String,
    total_nkill: f64,
    average_individual: f64,
    count: f64,
}

// ... 

    let groups = records
        .into_iter()
        .sorted_unstable_by(|a, b| Ord::cmp(&amp;a.country_txt, &amp;b.country_txt))
        .group_by(|record| record.country_txt.clone())
        .into_iter()
        .map(|(country, group)| {
            let (total_nkill, count, average_individual) = group.into_iter().fold(
                (0., 0., 0.),
                |(total_nkill, count, average_individual), record| {
                    (
                        total_nkill + record.nkill.unwrap_or(0.),
                        count + 1.,
                        average_individual + record.individual.unwrap_or(0.),
                    )
                },
            );
            GroupBy {
                country: country.unwrap(),
                total_nkill,
                average_individual: average_individual / count,
                count,
            }
        })
        .collect::&lt;Vec&lt;_&gt;&gt;();
    let mut wtr =
        csv::Writer::from_path(&quot;output_rust_groupby.csv&quot;)
            .unwrap();

    for group in &amp;groups {
        wtr.serialize(group)?;
    }
<span class="boring">}
</span></code></pre></pre>
<p>‌</p>
<p>Although this solution is not as elegant as Pandas groupby, it gives a lot of flexibility on the computation of the reduced fields. Again, thanks to Closures.</p>
<p>I think more reduction method other than <code>sum</code> and <code>fold</code> would greatly improve the development experience of map-reduce style operation in rust. We will then probably have equivalent experience between Rust and Pandas.</p>
<h3 id="performance-4"><a class="header" href="#performance-4">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Mem(Gb)</th></tr></thead><tbody>
<tr><td>Pandas</td><td>2.78s</td><td>2.5Gb</td></tr>
<tr><td><strong>Rust</strong></td><td><strong>2.0s🔥 -35%</strong></td><td><strong>1.7Gb🔥 -32%</strong></td></tr>
</tbody></table>
<p>Although the performance is better for Rust, I would advise using <strong>Pandas</strong> for map-reduce heavy application, as it seems more appropriate.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="mutation"><a class="header" href="#mutation">Mutation</a></h2>
<h3 id="pandas-3"><a class="header" href="#pandas-3">[Pandas]</a></h3>
<p>There are many ways to do mutation in Pandas, I usually do the following for performance and functional style:</p>
<pre><code class="language-python">df[&quot;computed&quot;] = df[&quot;nkill&quot;].map(lambda x: (x - 10) / 2 + x ** 2 / 3)
df.to_csv(&quot;python_output_map.csv&quot;)
</code></pre>
<h3 id="rust-2"><a class="header" href="#rust-2">[Rust]</a></h3>
<p>For mutation, the functional <code>iter</code> of Rust really makes this part a walk in the park:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    records.iter_mut().for_each(|x: &amp;mut DataFrame| {
        let nkill = match &amp;x.nkill {
            Some(nkill) =&gt; nkill,
            None =&gt; &amp;0.,
        };

        x.computed = Some((nkill - 10.) / 2. + nkill * nkill / 3.);
    });

    let mut wtr = csv::Writer::from_path(
        &quot;output_rust_map.csv&quot;,
    )?;
    for record in &amp;records {
        wtr.serialize(record)?;
    }
<span class="boring">}
</span></code></pre></pre>
<h3 id="performance-5"><a class="header" href="#performance-5">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Mem(Gb)</th></tr></thead><tbody>
<tr><td>Pandas</td><td>12.82s</td><td>4.7Gb</td></tr>
<tr><td><strong>Rust</strong></td><td><strong>1.58s🔥 -87%</strong></td><td><strong>1.7Gb🔥 -64%</strong></td></tr>
</tbody></table>
<p>This is where the difference really appeared to me. Pandas do not scale for line-by-line custom build lambda functions. Pandas would have been even worst if I had done an operation involving several columns.</p>
<p><strong>Rust</strong> is way better for line-by-line mutation natively.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="merging-1"><a class="header" href="#merging-1">Merging</a></h2>
<h3 id="python"><a class="header" href="#python">[Python]</a></h3>
<p>Merging in python is pretty efficient generally speaking, it goes like this in general:</p>
<pre><code class="language-python">df_country = pd.read_csv(
    &quot;/home/peter/Documents/TEST/RUST/terrorism/src/WDICountry.csv&quot;
)

df_merge = pd.merge(
    df, df_country, left_on=&quot;country_txt&quot;, right_on=&quot;Short_Name&quot;
)
df_merge.to_csv(&quot;python_output_merge.csv&quot;)
</code></pre>
<h3 id="rust-3"><a class="header" href="#rust-3">[Rust]</a></h3>
<p>For Rust, however, this is a tricky part as, with Struct, merging isn’t really a thing. For me, the rustiest way of doing a merge is by adding a nested field containing the other struct we want to join data with.</p>
<p>I  first created a new struct and a new heap for the new data:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[skip_serializing_none]
#[derive(Clone, Debug, Deserialize, Serialize)]
struct DataFrameCountry {
    #[serialize_always]
    SNA_price_valuation: Option&lt;String&gt;,
    #[serialize_always]
    IMF_data_dissemination_standard: Option&lt;String&gt;,
    #[serialize_always]
    Latest_industrial_data: Option&lt;String&gt;,
    #[serialize_always]
    System_of_National_Accounts: Option&lt;String&gt;,
    //...

// ...

    let mut records_country: Vec&lt;DataFrameCountry&gt; = Vec::new();
    let file = File::open(path_country)?;
    let transcoded = DecodeReaderBytesBuilder::new()
        .encoding(Some(WINDOWS_1252))
        .build(file);
    let mut rdr = csv::ReaderBuilder::new()
        .delimiter(b',')
        .from_reader(transcoded); 

    for result in rdr.deserialize() {
        match result {
            Ok(rec) =&gt; {
                records_country.push(rec);
            }
            Err(e) =&gt; println!(&quot;{}&quot;, e),
        };
    }
<span class="boring">}
</span></code></pre></pre>
<p>I then cloned this new struct with the previous struct on a specific field that is unique.</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span>
<span class="boring">fn main() {
</span>impl DataFrame {
    fn add_country_ext(&amp;mut self, country: Option&lt;DataFrameCountry&gt;) {
        self.country_merge = Some(country)
    }
}

//...

    for country in records_country {
        records
            .iter_mut()
            .filter(|record| record.country_txt == country.Short_Name)
            .for_each(|x| {
                x.add_country_ext(Some(country.clone()));
            });
    }
    let mut wtr =
        csv::Writer::from_path(&quot;output_rust_join.csv&quot;)
            .unwrap();
    for record in &amp;records {
        wtr.serialize(record)?;
    }
<span class="boring">}
</span></code></pre></pre>
<p>I cloned the data for convenience and also for better comparability, but a reference can be passed if you can manage it.</p>
<p>And there we go! 🚀</p>
<p>Except, a nested struct is not yet serializable in CSV for Rust -&gt; <a href="https://github.com/BurntSushi/rust-csv/pull/197">https://github.com/BurntSushi/rust-csv/pull/197</a></p>
<p>So I had to adapt it to:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl DataFrame {
    fn add_country_ext(&amp;mut self, country: Option&lt;DataFrameCountry&gt;) {
        self.country_ext = Some(format!(&quot;{:?}&quot;, country))
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>But, then, we got a sort of merge! 🚀</p>
<h3 id="performance-6"><a class="header" href="#performance-6">Performance</a></h3>
<table><thead><tr><th></th><th>Time(s)</th><th>Mem(Gb)</th></tr></thead><tbody>
<tr><td>Pandas</td><td>22.47s</td><td>11.8Gb</td></tr>
<tr><td><strong>Rust</strong></td><td><strong>5.48s🔥 -75%</strong></td><td><strong>2.6Gb🔥 -78%</strong></td></tr>
</tbody></table>
<p><strong>Rust</strong> is capable of doing nested structs that are going to be as capable if not more capable than <strong>Pandas</strong> merges. However, it isn’t really a one to one comparison and in this case, it is going to depend on your use case.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h2>
<p>After this experience, this is my take away.</p>
<ul>
<li>Use Pandas when you can: small CSV(&lt;1M lines), simple operation, data cleaning …</li>
<li>Use Rust when you have: complex operations, memory heavy or time-consuming pipelines, custom build functions, scalable software…</li>
</ul>
<p>That been said, Rust offers impressive flexibility compared to Pandas. Adding the fact that Rust is way more capable of multi-threading than Pandas, I believe that Rust can solve problems Pandas simply cannot.</p>
<p>Additionally, the possibility to run Rust on any platform(Web, Android, or Embedded) also create new opportunities for data manipulation in places inconceivable for Pandas and can provide solutions for yet to be resolved challenges.</p>
<h3 id="performance-7"><a class="header" href="#performance-7">Performance</a></h3>
<p>The performance table gives us an insight as to what to expect from Rust. I believe, the speedup can go from <strong>x2</strong> at the minimum and up to <strong>x50</strong> for large data pipelines. The memory use will have an even greater decrease as memory usage accumulates over time with python.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scraping-python-vs-rust"><a class="header" href="#scraping-python-vs-rust">Scraping Python vs Rust</a></h1>
<h2 id="error-handling"><a class="header" href="#error-handling">Error handling</a></h2>
<p>Web scraping is about as error-prone as you can imagine. Pages might not exist, HTML elements might not always be there… And so, a language that can support errors and edge cases well at runtime and not crash is a huge plus.</p>
<h3 id="python-1"><a class="header" href="#python-1">[Python]</a></h3>
<p>In python, the most common way to handle errors in code would be with an if-statement like so:</p>
<pre><code class="language-python">response = requests.get(URL)
if response.status_code == 200:
    content = response.content

    soup = bs.BeautifulSoup(content, 'lxml')
    articles = soup.find_all('article')
    if articles:
        ...
</code></pre>
<p>In itself, handling edge cases with  <code>if</code>  is not so bad and pretty natural. But, it has some drawbacks:</p>
<ul>
<li>It makes the code harder to read as it is difficult to dissociate business logic and error handling.</li>
<li>if-statements are most of the time added in retroaction of a bug, which makes coding slower and not fun.</li>
<li>if-statements error handling logic might vary between packages, which makes coding very tedious.</li>
</ul>
<h3 id="rust-4"><a class="header" href="#rust-4">[Rust]</a></h3>
<p>In Rust, functions return either a success or an error, and, you have to deal with each case before compiling. This makes the code way more robust against errors at runtimes. In practice, the code might look like this:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let name = match node.find(Name(&quot;h3&quot;)).next() {
    Some(h3) =&gt; h3.text(),
    None =&gt; &quot;&quot;.to_string(),
};
<span class="boring">}
</span></code></pre></pre>
<p>Rust also has other ways to handle Success / Errors Result, such as “?” à la Typescript:</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let response = reqwest::get(&amp;url).await?.text().await?;
<span class="boring">}
</span></code></pre></pre>
<p>The drawbacks are that developing in Rust is slower as you have to deal with every edge case during development.</p>
<p>Sometimes, it might even be tricky to understand which edge cases you’re trying to deal with. To be noted, that you HAVE to deal with every edge case in Rust otherwise, Rust will not compile. This is how serious Rust is about error handling.</p>
<h2 id="async-scraping"><a class="header" href="#async-scraping">Async scraping</a></h2>
<p>During scraping, most of the time is lost downloading file rather than computing.</p>
<p>However, with synchronous runtimes, pages are scraped one by one and so downloaded one by one. Each download can take time and idle the whole process. Therefore, if we can manage to not wait for the completion of each download, we will gain efficiency.</p>
<h3 id="python-2"><a class="header" href="#python-2">[Python]</a></h3>
<p>Unfortunately, Python does not perform well in asynchronous computing and it is also not thread-safe. But it is possible using the “asyncio” library, and it might look like that:</p>
<pre><code class="language-python">import asyncio
import requests
import bs4 as bs
import csv

URL = &quot;http://books.toscrape.com/catalogue/page-%d.html&quot;


async def get_book(url, spamwriter):
    response = requests.get(url)
    if response.status_code == 200:
        content = response.content
        soup = bs.BeautifulSoup(content, 'lxml')
        articles = soup.find_all('article')

        for article in articles:
            information = [url]
            information.append(article.find(
                'p', class_='price_color').text)
            information.append(article.find('h3').find('a').get('title'))
            spamwriter.writerow(information)


async def main():
    with open('./test_async_python.csv', 'w') as csvfile:
        spamwriter = csv.writer(csvfile, delimiter=',')
        tasks = []
        for i in range(1, 50):
            tasks.append(asyncio.create_task(
                get_book(URL % i, spamwriter)))

        for task in tasks:
            await task

asyncio.run(main())
</code></pre>
<p>Python does provide the <code>async/await</code> terminology which makes it easier to read and write.</p>
<h3 id="rust-5"><a class="header" href="#rust-5">[Rust]</a></h3>
<p>Rust, on the contrary to Python, has been built with asynchronous computation in mind. It is thread-safe and extremely efficient. The fact that the language, in its nature. is super fast makes it great for coroutines. The code might look like that:</p>
<pre><pre class="playground"><code class="language-rust">use csv::Writer;
use select::document::Document;
use select::predicate::{Attr, Class, Name};
use std::fs::OpenOptions;

async fn test(i: &amp;i32) -&gt; Result&lt;(), Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; {
    let url = format!(&quot;http://books.toscrape.com/catalogue/page-{}.html&quot;, i);
    let response = reqwest::get(&amp;url).await?.text().await?;
    let file = OpenOptions::new()
        .write(true)
        .create(true)
        .append(true)
        .open(&quot;test2.csv&quot;)
        .unwrap();
    let mut wtr = Writer::from_writer(file);

    let document = Document::from(response.as_str());

    for node in document.find(Name(&quot;article&quot;)) {
        let name = match node.find(Name(&quot;h3&quot;)).next() {
            Some(h3) =&gt; h3.find(Name(&quot;a&quot;)).next().unwrap().text(),
            None =&gt; &quot;&quot;.to_string(),
        };
        let price = node
            .find(Attr(&quot;class&quot;, &quot;price_color&quot;))
            .next()
            .unwrap()
            .text();

        println!(&quot;{:#?} &quot;, url);
        wtr.write_record(&amp;[&amp;url, &amp;price, &amp;name]).unwrap();
    }

    Ok(())
}

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {

    let mut handles: std::vec::Vec&lt;_&gt; = Vec::new();
    for i in 1..50 {
        let job = tokio::spawn(async move { test(&amp;i).await });
        handles.push(job);
    }

    let mut results = Vec::new();
    for job in handles {
        results.push(job.await);
    }

    Ok(())
}
</code></pre></pre>
<p>‌</p>
<h2 id="performance-8"><a class="header" href="#performance-8">Performance</a></h2>
<p>Performance test of scraping the 50 pages of <a href="http://books.toscrape.com/catalogue/page-2.html">http://books.toscrape.com/catalogue/page-1.html</a></p>
<table><thead><tr><th>Name</th><th>CPU Usage</th><th>Time(s)</th></tr></thead><tbody>
<tr><td>Synchronous Python</td><td>5%</td><td>44.363s</td></tr>
<tr><td>Synchronous Rust</td><td>7%</td><td>55s</td></tr>
<tr><td>Async Python</td><td>63%</td><td>2.5s</td></tr>
<tr><td>Async Rust</td><td>107%</td><td>2.25s</td></tr>
</tbody></table>
<p>‌</p>
<p>Performance are pretty similar due to the fact that web scraping is pretty much io bound.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
                        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
                
    </body>
</html>
