<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Deep Learning in Rust - Haixuan Xavier Tao</title>
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
                <link rel="stylesheet" href="custom.css">
        
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="about-me.html"><strong aria-hidden="true">1.</strong> About Me</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="work.html"><strong aria-hidden="true">1.1.</strong> Work Experience</a></li><li class="chapter-item expanded "><a href="education.html"><strong aria-hidden="true">1.2.</strong> Education</a></li><li class="chapter-item expanded "><a href="skills.html"><strong aria-hidden="true">1.3.</strong> Skills</a></li></ol></li><li class="chapter-item expanded "><a href="00-blog.html"><strong aria-hidden="true">2.</strong> Python vs Rust</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="01-pandas-vs-rust.html"><strong aria-hidden="true">2.1.</strong> Pandas vs Rust</a></li><li class="chapter-item expanded "><a href="02-polars-vs-rust.html"><strong aria-hidden="true">2.2.</strong> Pandas vs Polars </a></li><li class="chapter-item expanded "><a href="03-deep_learning_in_rust.html" class="active"><strong aria-hidden="true">2.3.</strong> Deep Learning in Rust</a></li></ol></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">Haixuan Xavier Tao</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="deep-learning-in-rust"><a class="header" href="#deep-learning-in-rust">Deep Learning in Rust</a></h1>
<p>I have searched for months for a way to do Deep Learning(DL) Inference with Rust on GPU and I finally did it!!‚ú®üëè‚ú® This blog post will try to answer if Rust is a good fit for the job!</p>
<p><em>I have put an annexe at the end with the definition of Deep Learning words.</em></p>
<h2 id="my-setup"><a class="header" href="#my-setup">My setup</a></h2>
<p>I am using a Hugging Face <strong>tokenizer</strong> and a custom <strong>BERT</strong> Model from Pytorch that I have converted to <strong>ONNX</strong> to be run with <a href="https://github.com/nbigaouette/onnxruntime-rs"><strong>onnxruntime-rs</strong></a><strong>.</strong></p>
<p>I have tweaked <a href="https://github.com/nbigaouette/onnxruntime-rs">onnxruntime-rs</a> to do Deep Learning on GPU with CUDA 11 and onnxruntime 1.8 You can check it out on my git: <a href="https://github.com/haixuanTao/onnxruntime-rs">https://github.com/haixuanTao/onnxruntime-rs</a></p>
<p>Hardware-side, I have a 6 cores/12 threads CPU and a GTX 1050 GPU.</p>
<h2 id="unit-results"><a class="header" href="#unit-results">Unit Results</a></h2>
<h3 id="1-inference-time"><a class="header" href="#1-inference-time">1. Inference time</a></h3>
<table><thead><tr><th></th><th>Inferencing time per phrase</th><th>Speedup</th></tr></thead><tbody>
<tr><td>(Rust or Python) ONNX CPU</td><td>~125ms</td><td></td></tr>
<tr><td>(Rust or Python) ONNX GPU</td><td>~10ms</td><td><strong>x12</strong>üî•</td></tr>
</tbody></table>
<p><strong>DL inference using Onnxruntime will not be faster in Rust because both are wrapping the same C++ underlying engine. What is going to make a difference is the GPU.</strong></p>
<h3 id="2-preprocessing-time"><a class="header" href="#2-preprocessing-time">2. Preprocessing time</a></h3>
<table><thead><tr><th></th><th>Tokenizing time per phrase</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Python BertTokenizer</td><td>1000Œºs</td><td></td></tr>
<tr><td>Python BertTokenizerFast</td><td>200-600Œºs</td><td><strong>x2.5</strong>üî•</td></tr>
<tr><td>Rust <a href="https://docs.rs/tokenizers/0.10.1/tokenizers/">Tokenizer</a></td><td>50-150Œºs</td><td><strong>x4</strong>üî•</td></tr>
</tbody></table>
<p><strong>Gains can be made on DL Preprocessing! You can tokenize 4 times faster in Rust compared to Python, with the same Hugging Face Tokenizer library.</strong></p>
<h2 id="case-studies-results"><a class="header" href="#case-studies-results">Case studies Results</a></h2>
<p>Looking at those results alone is not enough. To dig a little further, I have built a DL data pipeline for batch inference and a DL server, to see what Rust for DL could be like on a daily basis.</p>
<h3 id="1-deep-learning-batch-inference-running-bert-on-a-csv"><a class="header" href="#1-deep-learning-batch-inference-running-bert-on-a-csv">1. Deep Learning batch inference: Running BERT on a CSV</a></h3>
<p>Let say you want the inference of a BERT model on one column of a 10 thousand lines CSV.</p>
<p>On my setup, I got those timings:</p>
<table><thead><tr><th>10k phrases</th><th>Python</th><th>Rust</th></tr></thead><tbody>
<tr><td>Booting time</td><td>4s</td><td>1s</td></tr>
<tr><td>Encoding time</td><td>0.7s</td><td>0.3s</td></tr>
<tr><td>DL Inference time</td><td>75s</td><td>75s</td></tr>
<tr><td>Total time</td><td>80s</td><td>76s</td></tr>
<tr><td>Memory usage</td><td>1 GiB</td><td>0.7 GiB</td></tr>
</tbody></table>
<p><strong>As DL inference is taking the majority of the time, Rust will not increase performance and I would not bother with Rust and stay with Python for large batches of inference.</strong>   üëçüêç</p>
<p><em>Git:</em>  <a href="https://github.com/haixuanTao/bert-onnx-rs-pipeline"><em>https://github.com/haixuanTao/bert-onnx-rs-pipeline</em></a></p>
<h3 id="2-onnx-server-serving-bert-as-an-api"><a class="header" href="#2-onnx-server-serving-bert-as-an-api">2. ONNX Server: Serving BERT as an API</a></h3>
<p>Let say you want to serve a BERT-like model through a server API endpoint.</p>
<p>On my setup, I got those metrics:</p>
<table><thead><tr><th></th><th>Python FastAPI</th><th>Rust Actix Web</th><th>Speedup</th></tr></thead><tbody>
<tr><td>Encoding time</td><td>400Œºs</td><td>100Œºs</td><td></td></tr>
<tr><td>ONNX Inference time</td><td>~10ms</td><td>~10ms</td><td></td></tr>
<tr><td>API overhead time</td><td>~2ms</td><td>~1ms</td><td></td></tr>
<tr><td>Mean Latency</td><td>12.8ms</td><td>10.4ms</td><td>-20%‚è∞</td></tr>
<tr><td>Requests/secs</td><td>77.5 #/s</td><td>95 #/s</td><td>+22%üçæ</td></tr>
</tbody></table>
<p><strong>The gain in performance comes from moving from considered ‚ÄúFast‚Äù Python library to Rust: FastAPI -&gt; Actix Web, BertokenizerFast -&gt; Rust Tokenizer.</strong></p>
<p><strong>Thus, as Rust libraries tend to be faster than Python ones, the more functionalities you will have, the more speedup you‚Äôre going to see with Rust when serving Deep Learning.</strong></p>
<p><strong>That‚Äôs why, for performance-centric Deep Learning applications such as Real-Time Deep Learning, Embedded Deep Learning, Large-Scale AI servers ‚Ä¶. I can definitely see Rust be a good fit!</strong> ‚ù§Ô∏è‚Äçü¶Ä</p>
<p><em>Git:</em> <a href="https://github.com/haixuanTao/bert-onnx-rs-server"><em>https://github.com/haixuanTao/bert-onnx-rs-server</em></a></p>
<h3 id="in-conclusion-should-you-use-rust-for-deep-learning"><a class="header" href="#in-conclusion-should-you-use-rust-for-deep-learning">In conclusion, should you use Rust for Deep Learning?</a></h3>
<ul>
<li>Like the whole Rust ecosystem, you should use it if it‚Äôs the best tool for the job. If you really need performance üèéÔ∏è and resilienceüõ°Ô∏è, and you are ok to have a stack in Rust, go aheadüöÄ! But be aware that making Rust fast is not easy!</li>
<li>If you need quick prototyping with a data scientist friendly language, you should better use Python!</li>
</ul>
<p>‚Äå</p>
<p><strong>There will be a following blog post around the actual implementation of the DL pipeline and server so make sure to follow along</strong> üòÄ :</p>
<ul>
<li>On able: <a href="https://able.bio/haixuanTao">https://able.bio/haixuanTao</a></li>
<li>On github: <a href="https://github.com/haixuanTao">https://github.com/haixuanTao</a></li>
<li>On linkedin: <a href="https://www.linkedin.com/in/haixuan-xavier-tao-7460b1102/">https://www.linkedin.com/in/haixuan-xavier-tao-7460b1102/</a></li>
</ul>
<p>‚Äå</p>
<p>‚Äå</p>
<p>‚Äå</p>
<p>‚Äå</p>
<h3 id="git-reference"><a class="header" href="#git-reference">Git reference</a></h3>
<p><em>Git of my tweaked onnxruntime-rs library with ONNX 1.8 and GPU features with CUDA 11:</em> <a href="https://github.com/haixuanTao/onnxruntime-rs">https://github.com/haixuanTao/onnxruntime-rs</a></p>
<p><em>Git of bert - onnxruntime-rs - Pipeline:</em>  <a href="https://github.com/haixuanTao/bert-onnx-rs-pipeline"><em>https://github.com/haixuanTao/bert-onnx-rs-pipeline</em></a></p>
<p><em>Git of bert - onnxruntime-rs - actix - server:</em> <a href="https://github.com/haixuanTao/bert-onnx-rs-server"><em>https://github.com/haixuanTao/bert-onnx-rs-server</em></a></p>
<p>‚Äå</p>
<h3 id="annexe"><a class="header" href="#annexe">Annexe</a></h3>
<p><a href="https://onnx.ai/">ONNX</a> is an open format built to represent machine learning models. You can convert Pytorch, Tensorflow and Sklearn models into an ONNX format and then run them with <a href="https://github.com/nbigaouette/onnxruntime-rs">onnxruntime</a>.</p>
<p><a href="https://www.onnxruntime.ai/">ONNXRuntime</a> is the inference and optimized training engine that can read and run ONNX model. It is written in C++. There are official wrappers for Python, JS, JAVA, C and C++.</p>
<p><a href="https://github.com/nbigaouette/onnxruntime-rs">Onnxruntime-rs</a> is the Onnxruntime wrapper for Rust, it is a community-developed solution and does not wrap all the features of the C++ engine. I have tweaked the initial repo in order to have version 1.8 of Onnxruntime with the possibility of running it in GPU. My version is here: <a href="https://github.com/haixuanTao/onnxruntime-rs">https://github.com/haixuanTao/onnxruntime-rs</a> with branch onnx1.8.</p>
<p><a href="https://huggingface.co/transformers/main_classes/tokenizer.html">Tokenizer</a> enables you to transform words into index given a list of word.</p>
<p><a href="https://huggingface.co/transformers/model_doc/bert.html">BERT</a> is a Deep Learning model used for natural language processing.</p>
<p><a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPU</a> is a graphical processing unit for parallel computing. You will need CUDA and therefore an NVIDIA GPU to run Onnxruntime-rs.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                                                    <a rel="prev" href="02-polars-vs-rust.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                                    <a rel="prev" href="02-polars-vs-rust.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
        
    </body>
</html>
